{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# NLP Using the Twitter API: Guided Lab\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<img src=\"https://snag.gy/RNAEgP.jpg\" width=\"600\">\n",
    "\n",
    "### Can We Correctly Identify Which of These Men Tweeted What?\n",
    "\n",
    "> *Note: This lab is intended to be a guided lab until the independent practice questions.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "---\n",
    "\n",
    "We're going to attempt to classify whether a tweet comes from Donald Trump or Bernie Sanders. This lab involves multiple steps:\n",
    "- Create a developer account on Twitter.\n",
    "- Create a method to pull a list of tweets from the Twitter API.\n",
    "- Perform proper preprocessing on our text.\n",
    "- Engineer sentiment features in our data set using `TextBlob`.\n",
    "- Explore supervised classification techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter API Developer Registration\n",
    "---\n",
    "\n",
    "If you haven't registered for a Twitter account, do so now in order to have a developer account for this lab.\n",
    "\n",
    "[Twitter Rest API](https://dev.twitter.com/rest/public)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an App\n",
    "\n",
    "---\n",
    "\n",
    "![](https://snag.gy/HPBQbJ.jpg)\n",
    "\n",
    "Go to Twitter and register an app: [apps.twitter.com](https://apps.twitter.com/).\n",
    "\n",
    "> **Note**: For the required website field, you can put a placeholder.\n",
    "\n",
    "After you set up your application, you’ll only need to reference the corresponding keys Twitter generates for it. These are the keys that we'll use with our application to communicate with the Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Python Twitter API Library\n",
    "\n",
    "---\n",
    "\n",
    "Someone was nice enough to build a Python library for us, which makes pulling tweets simple: We only need to plug in our keys to start collecting data. The library we'll be using is provided by [Python Twitter Tools](http://mike.verdone.ca/twitter/).\n",
    "\n",
    "To install it, just run the next frame (there is no conda package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: do NOT install the library \"twitter\" (with pip), \n",
    "# it's a different library and has a different interface!\n",
    "\n",
    "#!pip install twitter python-twitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Twitter Rules\n",
    "---\n",
    "\n",
    "**Twitter notifies you that your requests have a rate limit.**\n",
    "\n",
    "> When using application-only authentication, rate limits are determined globally for the entire application. If a method allows for 15 requests per rate-limit window, then it allows you to make 15 requests per window on behalf of your application. This limit is considered separately from per-user limits. https://dev.twitter.com/rest/public/rate-limiting\n",
    "\n",
    "Here's a quick overview of Twitter's rules:\n",
    "\n",
    "![](https://snag.gy/yJ6vIH.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About Those Keys: OAuth Review\n",
    "---\n",
    "\n",
    "![](https://g.twimg.com/dev/documentation/image/appauth_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Going On Here?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Application Keys\n",
    "---\n",
    "\n",
    "Take note of the application keys you’ll use to connect to Twitter and mine tweets from the official Bernie Sanders and Donald Trump accounts.\n",
    "\n",
    "![](https://snag.gy/H1djQK.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `TweetMiner` Class Structure\n",
    "\n",
    "---\n",
    "\n",
    "The following code will get you up and running by providing connectivity to Twitter. The class has the ability to make requests and can eventually transform the JSON responses into DataFrames.\n",
    "\n",
    "This is a great example of using object-oriented Python to organize our code.\n",
    "\n",
    "> **Note:** `request_limit` is used in this class to limit the number of tweets that are pulled per instance request. Setting it to something lower until you've worked out the bugs in your request and captured the data you want is essential for avoiding rate limit blocks.\n",
    "\n",
    "### Twitter API Key Set Up\n",
    "\n",
    "Fill the information below in with the keys for your account.\n",
    "\n",
    "- **consumer_key**: Find this on your application page under the Keys and Access Tokens tab.\n",
    "- **consumer_secret**: This is located right under **consumer_key** in the Keys and Access Tokens tab.\n",
    "- **access_token_key**: To get this, you'll need to click the button to generate tokens.\n",
    "- **access_token_secret**: This is available after you generate tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip uninstall twitter -y\n",
    "# !pip install python-twitter\n",
    "\n",
    "# NOTE: do NOT install the library \"twitter\" (with pip), \n",
    "# it's a different library and has a different interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter, re, datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Your keys go here:\n",
    "twitter_keys = {\n",
    "    'consumer_key':        'lA6UQplM5sxIAFr83ueUl9sgE',\n",
    "    'consumer_secret':     'f94t4BD6Vj7aCVkX1qAIVwsP4x69J2vXvm61FTIuwb9GfmdsuP',\n",
    "    'access_token_key':    '1203210464-FYE1FvoUx1GjVcoyok3U1brWDpELBJEcSNGC1OC',\n",
    "    'access_token_secret': 'kuVli1j010RPdYTbozFiIyp8QxX6PqRApdi49baLqBgzo'\n",
    "}\n",
    "\n",
    "api = twitter.Api(\n",
    "    consumer_key         =   twitter_keys['consumer_key'],\n",
    "    consumer_secret      =   twitter_keys['consumer_secret'],\n",
    "    access_token_key     =   twitter_keys['access_token_key'],\n",
    "    access_token_secret  =   twitter_keys['access_token_secret']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TweetMiner(object):\n",
    "\n",
    "    result_limit    =   20    \n",
    "    api             =   False\n",
    "    data            =   []\n",
    "    \n",
    "    def __init__(self, keys_dict, api, result_limit = 20):\n",
    "        \n",
    "        self.api = api\n",
    "        self.twitter_keys = keys_dict\n",
    "        \n",
    "        self.result_limit = result_limit\n",
    "        \n",
    "\n",
    "    def mine_user_tweets(self, user=\"dyerrington\", mine_rewteets=False, max_pages=5):\n",
    "\n",
    "        data           =  []\n",
    "        last_tweet_id  =  False\n",
    "        page           =  1\n",
    "        \n",
    "        while page <= max_pages:\n",
    "            \n",
    "            if last_tweet_id:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit, max_id=last_tweet_id - 1)        \n",
    "            else:\n",
    "                statuses   =   self.api.GetUserTimeline(screen_name=user, count=self.result_limit)\n",
    "                \n",
    "            for item in statuses:\n",
    "\n",
    "                mined = {\n",
    "                    'tweet_id':        item.id,\n",
    "                    'handle':          item.user.name,\n",
    "                    'retweet_count':   item.retweet_count,\n",
    "                    'text':            item.text,\n",
    "                    'mined_at':        datetime.datetime.now(),\n",
    "                    'created_at':      item.created_at,\n",
    "                }\n",
    "                \n",
    "                last_tweet_id = item.id\n",
    "                data.append(mined)\n",
    "                \n",
    "            page += 1\n",
    "            \n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instantiate the Class\n",
    "---\n",
    "\n",
    "Make sure you pass the keys dictionary and the API as arguments.\n",
    "\n",
    "**Check:** Call the object's `mine_user_tweets()` method, providing a user from whom to pull tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the Tweet Outputs to a Pandas DataFrame\n",
    "\n",
    "> *Hint: This is as easy as passing it to the DataFrame constructor!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##  Create the Training Data\n",
    "\n",
    "---\n",
    "\n",
    "Let's get our mined data from the Twitter API.  \n",
    "\n",
    "- Mine Trump tweets.\n",
    "- Create a tweet DataFrame.\n",
    "- Mine Sanders tweets.\n",
    "- Append the results to our DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Are There Any Interesting N-Grams Going on With Trump?\n",
    "---\n",
    "\n",
    "Set up a vectorizer from scikit-learn and fit the text of Trump's tweets with an n-gram range of two to four. Identify the most common n-grams.\n",
    "\n",
    "> **Note:** It's up to you whether or not you want to remove stop words. How does keeping or removing stop words affect the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the N-Grams for Bernie Sanders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing the Tweets and Building a Model\n",
    "\n",
    "---\n",
    "\n",
    "To perform classification, we'll need to convert the tweets into a set of features.\n",
    "\n",
    "**You will need to:**\n",
    "- Vectorize and input text data.\n",
    "- Initialize a model (try logistic regression).\n",
    "- Train, predict, and cross-validate.\n",
    "- Evaluate the performance of the model.\n",
    "\n",
    "> **Bonus:** You may have noticed that there are website links in the tweets. What additional preprocessing steps can you take before building the model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check the Predicted Probability for a Random Sanders and Trump Tweet\n",
    "---\n",
    "\n",
    "A couple of tweets from both Sanders and Trump are provided below. \n",
    "\n",
    "Estimate the predicted probability of Trump being the author for the two tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prep our source as TF-IDF vectors.\n",
    "source_test = [\n",
    "    \"Demanding that the wealthy and the powerful start paying their fair share of taxes that's exactly what the American people want.\",\n",
    "    \"Crooked Hillary is spending tremendous amounts of Wall Street money on false ads against me. She is a very dishonest person!\"\n",
    "]\n",
    "\n",
    "############\n",
    "# Note: Do not re-initialize the TF-IDF vectorizer or the feature space will be overwritten and\n",
    "# your transform will not match the number of features on which you trained your model.\n",
    "#\n",
    "# You only need to transform because you fit previously.\n",
    "#\n",
    "####\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Independent Practice Questions\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Pull tweets for some new users.\n",
    "\n",
    "Experiment with using more data. The API will not like it if you blow through its limits, so be careful. Try to grab only what you need one time, then work on the copy of the objects that are returned.  \n",
    "\n",
    "> Read the documentation about rate limits and see if you can get enough without hitting the limit. Are there any options available in the API to avoid such a problem?\n",
    "\n",
    "**Pull tweets for more than two different users of your choice.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Build a multi-class classification model to distinguish between the users.\n",
    "\n",
    "Try a different model than what we used before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create a confusion matrix and a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) What are the most and least \"distinctive\" tweets for each user?\n",
    "\n",
    "To find this, identify the tweet that has the highest (correct) predicted probability of being that user's tweet for each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
