{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to Statsmodels and Scikit-Learn\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://avatars2.githubusercontent.com/u/365630?v=3&s=400\" style=\"width: 300px; float: left; margin: 20px; margin-top: -20px; break: right;\"><img src=\"https://snag.gy/qfaubJ.jpg\" style=\"width: 300px; float: left; margin: 20px;\"> \n",
    "\n",
    "<br clear=\"all\">\n",
    "\n",
    "\n",
    "### Learning Objectives\n",
    "- Review the uses of statsmodels and scikit-learn modules. \n",
    "- Learn how to build a linear regression model with scikit-learn.\n",
    "- Practice building models using scikit-learn.\n",
    "- Learn how to build a linear regression model using statsmodels.\n",
    "- Understand the practical differences between scikit-learn and statsmodels.\n",
    "- Interpret the output of models from both packages.\n",
    "- Learn how to create formulas using the Patsy module to easily specify target and predictor matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Scikit-Learn & Statsmodels](#intro)\n",
    "- [Looking at the Documentation](#documentation)\n",
    "- [History of Scikit-Learn](#sklearn-background)\n",
    "- [First Steps With Scikit-Learn](#sklearn-first-steps)\n",
    "- [Fitting a Model With Scikit-Learn](#first-model-sklearn)\n",
    "- [scikit-learn Model Class Attributes](#model-attributes)\n",
    "- [Review Metrics for Evaluating Regression Models](#common-metrics)\n",
    "- [Fit an MLR Using Scikit-Learn](#mlr-sklearn)\n",
    "- [A Note on Negative $R^2$ Values](#negative-r2)\n",
    "- [Fitting a Linear Regression Using Statsmodels](#statsmodels-intro)\n",
    "- [Statsmodels' `.summary()` Function](#statsmodels-summary)\n",
    "- [Independent Practice](#independent-practice)\n",
    "- [A Brief Introduction to `Patsy` Formulas](#patsy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "##  Scikit-Learn & Statsmodels\n",
    "\n",
    "---\n",
    "\n",
    "This lesson intends to introduce the modeling packages `scikit-learn` and `statsmodels` in the context of regression modeling. These are both powerful Python packages with different strengths. \n",
    "\n",
    "In general:\n",
    "- **Scikit-learn** is the *machine learning* package.\n",
    "- **Statsmodels** is the *statistics* package.\n",
    "\n",
    "Although the terms have immense overlap, machine learning tends to be more focused on prediction while statistics is more focused on inference. \n",
    "\n",
    "**Remember: Even with all the power these modeling tools provide, they'll never replace good EDA!**\n",
    "\n",
    "---\n",
    "\n",
    "### A Preface on Modeling\n",
    "\n",
    "As we venture down the path of modeling, it can be difficult to determine which choices are \"correct\" or \"incorrect.\"  A primary challenge is to understand how various models will perform in different circumstances and with different types of data. Thus, it is essential to practice modeling on a variety of data.\n",
    "\n",
    "As a beginner, it is imperative to learn which metrics are important for evaluating your models and what those metrics mean. The metrics with which we evaluate our models will inform our actions.  \n",
    "\n",
    "*We highly recommend exploring data sets on your own with the skills and tools you learn in this course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='documentation'></a>\n",
    "\n",
    "## Scikit-Learn and Statsmodels Documentation\n",
    "\n",
    "---\n",
    "\n",
    "Get familiar with searching the scikit-learn and statsmodels documentation. You'll be doing this often throughout this course and beyond.\n",
    "\n",
    "The statsmodels documentation can be found [here](http://statsmodels.sourceforge.net/devel/). Many recommend using the bleeding-edge version of statsmodels. For that, you can [reference the code on GitHub](https://github.com/statsmodels/statsmodels/).\n",
    "\n",
    "The scikit-learn documentation can be found [here](http://scikit-learn.org/stable/documentation.html).\n",
    "\n",
    "The packages have different approaches and syntax for constructing models. Below are examples for linear regression in each package:\n",
    "* [Linear regression in statsmodels](http://statsmodels.sourceforge.net/devel/examples/#regression).\n",
    "* [Linear regression in scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html).\n",
    "\n",
    "If you haven't yet, familiarize yourself with the format of the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sklearn-background'></a>\n",
    "\n",
    "## Background: Scikit-Learn\n",
    "\n",
    "---\n",
    "\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/25111?v=3&s=200\" style=\"float: left; margin: 0 25px;\"> Scikit-learn was founded in 2007 as a Google Summer of Code project by [David Cournapeau](https://github.com/cournape). Later that year, Matthieu Brucher published his thesis on scikit-learn. Since then, the scikit-learn project has taken on a worldwide team of owners. A great high-level overview of the project can be found in a 2011 publication, the [Journal of Machine Learning Research 12 (2011) 2825-2830](http://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf).\n",
    "\n",
    "Scikit-learn is part of the SciPy family of \"kits.\" Explore some of the other projects in this family [here](https://scikits.appspot.com/scikits).\n",
    "<br clear=\"all\"><br>\n",
    "\n",
    "\n",
    "**Scikit-learn provides a wide variety of machine learning models, including:**\n",
    "\n",
    "- Linear regression\n",
    "- Logistic regression\n",
    "- Support vector machines (SVM)\n",
    "- Classification and regression tree (CART) models\n",
    "- Naive Bayes\n",
    "- Clustering models (k-means, hierarchical, DBScan)\n",
    "\n",
    "**It also handles the construction of typical machine learning pipeline utilities for:**\n",
    "- Model evaluation\n",
    "- Model selection\n",
    "- Preprocessing\n",
    "- Natural language processing\n",
    "- Dimensionality reduction\n",
    "\n",
    "**Scikit-learn comes with a number of data sets that are cleaned and formatted to work with the models provided by their libraries:**\n",
    "- Boston housing\n",
    "- Iris flowers\n",
    "- Diabetes diagnostics\n",
    "- Various sample images (for classification)\n",
    "  - Faces\n",
    "  - MINIST (handwriting examples)\n",
    "- Random data generators\n",
    "- Spam examples\n",
    "- Newsgroup classification\n",
    "\n",
    "Read more about scikit-learn data sets [here](http://scikit-learn.org/stable/datasets/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn Under the Hood\n",
    "\n",
    "- **NumPy**: NumPy is the base for data structures and transformations. Input data is represented as NumPy arrays, integrating seamlessly with other scientific Python libraries. NumPyâ€™s view-based memory model limits copies, even when binding with compiled code. It also provides basic arithmetic and linear algebra operations.<br><br>\n",
    "\n",
    "- **SciPy**: SciPy provides efficient algorithms for linear algebra, sparse matrix representation, special functions, and basic statistical functions.<br><br>\n",
    "\n",
    "- **Cython**: Cython is a language for combining C with Python. Cython makes it easy to reach the performance of compiled languages with Python-like syntax and high-level operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sklearn-first-steps'></a>\n",
    "\n",
    "## First Steps With Scikit-Learn: Loading the Data\n",
    "\n",
    "---\n",
    "\n",
    "We will load the Boston housing data set using scikit-learn and then construct and fit a linear regression model on the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Don't forget to turn on plotting display in the notebook.\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the Boston housing data with the `datasets.load_boston()` function.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The data object we've loaded has attributes with the features, target variable, and design matrix:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting the Data in Pandas for Convenience\n",
    "\n",
    "Our target is the value we are predicting. Sometimes this is called the **response variable**.\n",
    "\n",
    "The target and the data are what we use to train, or **fit** the model.\n",
    "\n",
    "Scikit-learn has already done the work of splitting our data into **predictors** and **responses**. It has also stored the names of the features in a separate array. \n",
    "\n",
    "It will be more convenient to have our data in a Pandas DataFrame so that we can print things like the header of the data, for example.\n",
    "\n",
    "**Use the predictors and the feature names to create a Pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training set is a matrix/DataFrame with many variables (**CRI, ZN, INDUS, CHAS, NOX, RM, AGE, DIS, RAD, TAX, PTRATIO, B,** and **LSTAT**). We have **13** predictors with **506** rows/observations.\n",
    "\n",
    "Our target is a vector that represents a single variable (**MEDV**), which has exactly the same number of observations as our training set, **506** in this case.\n",
    "\n",
    "> _Training (fit) and target data sets must always match in length._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Correspondence Between Target and Predictors\n",
    "\n",
    "Row 0 of **`df`**, our training data, is:\n",
    "\n",
    "```\n",
    "[0.00632\t18.0\t2.31\t0.0\t0.538\t6.575\t65.2\t4.0900\t1.0\t296.0\t15.3\t396.90\t4.98]\n",
    "```\n",
    "\n",
    "This corresponds to the 0 index observation in our target vector:\n",
    "```\n",
    "24.0\n",
    "```\n",
    "\n",
    "These two separate data sets (a matrix/DataFrame and a vector), are what we will use in the `.fit(predictors, target)` function in scikit-learn's models.  \n",
    "\n",
    "- The training data is 2-D with the dimensions `n_samples` by `n_features`.\n",
    "- The response is 1-D with the single-dimension `n_samples`, matching the `n_samples` of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first-model-sklearn'></a>\n",
    "\n",
    "## Fitting a Model With Scikit-Learn\n",
    "\n",
    "---\n",
    "\n",
    "Now let's fit a linear regression model with the housing data. \n",
    "\n",
    "First let's visually identify some predictors that seem to have a relationship with house value. \n",
    "\n",
    "**Plot RM and LSTAT against the target variable with Seaborn.** \n",
    "\n",
    "> _Note: If for some reason scikit-learn crashes the Jupyter notebook, have conda remove mkl (there's an issue with the newer build on some systems)._\n",
    "```bash\n",
    "conda remove --features mkl\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Below we fit a linear regression model predicting `MEDV` (the target vector) from `RM`.**\n",
    "\n",
    "> **Note:** Scikit-learn models expect the predictor matrix to be 2-D and the target to be 1-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lm = linear_model.LinearRegression()\n",
    "\n",
    "# X = df[[\"RM\"]]\n",
    "# y = target \n",
    "\n",
    "# model = lm.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make predictions for the X matrix using `.predict(X)`, and score the model ($R^2$) using `model.score(X,y)`.**\n",
    "\n",
    "Plot the predicted values against the true values of the target, and print the model $R^2$.\n",
    "\n",
    "> **`.score(predictors,target)`**: a class method/function that returns the coefficient of determination $R^2$ of the prediction (for regression models). This is found in many models in scikit-learn, but not all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What can this plot tell us about the model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model-attributes'></a>\n",
    "\n",
    "## Scikit-Learn Model Class Attributes\n",
    "\n",
    "---\n",
    "\n",
    "After you run `.fit()`, a scikit-learn model object often contains a variety of calculated metrics, coefficients, and other information. Which metrics and attributes are present will depend on the model â€“ consult the documentation for specifics. \n",
    "\n",
    "Attributes in the `LinearRegression` object include:\n",
    "- **`.coef_`**: property containing the coefficients for the predictor variables.\n",
    "- **`.intercept_`**: value of the intercept.\n",
    "\n",
    "**Print out the beta coefficient and intercept for the model.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does the coefficient mean in the context of your model?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='common-metrics'></a>\n",
    "\n",
    "## Review: Common Metrics for Evaluating Regression Models\n",
    "\n",
    "---\n",
    "\n",
    "The [root mean squared error (RMSE)](https://en.wikipedia.org/wiki/Root-mean-square_deviation) is a standard measure of model performance. It is the square root of the mean of the sum of squared residuals:\n",
    "\n",
    "### $$ \\operatorname{RMSE}= \\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\hat{y_i} - y_i)^2} $$\n",
    "\n",
    "The smaller the root mean squared error, the better your model fits your data. \n",
    "\n",
    "You are already familiar with the [coefficient of determination $R^2$](https://en.wikipedia.org/wiki/Coefficient_of_determination):\n",
    "\n",
    "### $$ R^2 = 1 - \\frac{SS_{reg}}{SS_{tot}} $$\n",
    "\n",
    "Where the regression sum of squares is the sum of squared residuals for our model:\n",
    "\n",
    "$SS_{reg}=\\sum_i (\\hat{y} -\\bar{y})^2$\n",
    "\n",
    "And the total sum of squares is the sum of squared residuals for the *baseline* model. This is essentially the variance of our target.\n",
    "\n",
    "$SS_{tot} = \\sum_i (y_i-\\bar{y})^2$\n",
    "\n",
    "$R^2$ is the most common metric to evaluate a regression and is the default scoring measure in scikit-learn. When we cover classification models, the `.score` function instead defaults to accuracy.\n",
    "\n",
    "\n",
    "**Calculate the RMSE of your model by leveraging `sklearn.metrics.mean_squared_error`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='mlr-sklearn'></a>\n",
    "\n",
    "## Fit an MLR Using Scikit-Learn\n",
    "\n",
    "---\n",
    "\n",
    "We have fit a simple linear regression predicting `MEDV ~ RM + 1` (where the 1 represents the intercept). Use the same scikit-learn process and `LinearRegression` model to estimate the target with both `RM` and `LSTAT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the coefficients from this MLR model and interpret them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='negative-r2'></a>\n",
    "\n",
    "## A Note on Negative $R^2$ Values\n",
    "\n",
    "---\n",
    "\n",
    "Throughout this course, you will encounter negative $R^2$ values. This may seem impossible - and it is, in the standard scenario where we are calculating the $R^2$ score on the data with which we fit the model.\n",
    "\n",
    "However, if you fit your model on one sample of data *then score the model on new data not used to fit the model*, it is possible to end up with negative $R^2$.\n",
    "\n",
    "**What does it mean to have a negative $R^2$?**\n",
    "\n",
    "Remember that $R^2$ is 1 minus the error of your regression model divided by the error of the baseline model. A negative $R^2$ means that the regression model is performing *worse* than the baseline model. In the context of fitting our model on one sample of data and scoring on another sample, this means that we would have been better off simply using the mean of the target variable in our training set to make predictions on the test sample.\n",
    "\n",
    "We will return to the topic of negative $R^2$ when we talk about training and testing sets and cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='statsmodels-intro'></a>\n",
    "\n",
    "## Fitting a Linear Regression Using Statsmodels\n",
    "\n",
    "---\n",
    "\n",
    "Now we will fit the linear regression model predicting the target from `RM` and `LSTAT` â€” this time using statsmodels.\n",
    "\n",
    "The format looks like:\n",
    "\n",
    "```python\n",
    "import statsmodels.api as sm\n",
    "\n",
    "X = df[[\"RM\",\"LSTAT\"]].values\n",
    "# Manually add the intercept column:\n",
    "X = np.concatenate([X, np.ones((X.shape[0], 1))], axis=1)\n",
    "y = target\n",
    "\n",
    "model = sm.OLS(y, X)\n",
    "model = model.fit()\n",
    "predictions = model.predict()\n",
    "```\n",
    "\n",
    "First we load the statsmodels API module, which contains the ordinary least squares (`OLS`) model class. The statsmodels process is slightly different:\n",
    "- We manually make a new column for the intercept in our design matrix, $X$.\n",
    "- The $y$ target variable comes before the $X$ predictor.\n",
    "- The data are provided during the instantiation of the model object, then `.fit()` is called without the data.\n",
    "\n",
    "**Fit the model using statsmodels.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='statsmodels-summary'></a>\n",
    "\n",
    "### Statsmodels' `.summary()`  Function\n",
    "\n",
    "Once a model is fit with statsmodels, you can print out a variety of summary statistics, metrics, and properties of the model using the `model.summary()` function.\n",
    "\n",
    "You are already familiar with some of the information available in the summary:\n",
    "- R-squared.\n",
    "- Number of observations.\n",
    "- Coefficients for the variables and the intercept (const).\n",
    "- Standard errors of the coefficients, t-statistics, p values, and confidence intervals.\n",
    "\n",
    "There are also a variety of metrics that we haven't discussed yet. Don't hesitate to look up any of the statistics online if you are curious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='independent-practice'></a>\n",
    "\n",
    "## Independent Practice\n",
    "\n",
    "---\n",
    "\n",
    "Using either scikit-learn or statsmodels (or both, if you prefer), build a model using any set of **continuous** variables you choose. Evaluate your model using $R^2$. Describe what the $R^2$ means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='patsy'></a>\n",
    "\n",
    "## A Brief Introduction to Patsy Formulas\n",
    "\n",
    "---\n",
    "\n",
    "Why slice and dice the data yourself when you just need to write a formula that defines your model?\n",
    "\n",
    "The Patsy package allows you to specify the construction of your model using a formula string and then returns the matrices required to fit that model.\n",
    "\n",
    "Let's say we wanted to predict `CRIM` from `TAX`, `AGE` and `ZN`. We would write a string formula like so:\n",
    "\n",
    "```\n",
    "formula = 'CRIM ~ TAX + AGE + ZN'\n",
    "```\n",
    "\n",
    "Then, after importing Patsy, we can generate our target and predictor matrix by supplying the formula and the DataFrame that contains the corresponding columns.\n",
    "\n",
    "```python\n",
    "import patsy\n",
    "\n",
    "y, X = patsy.dmatrices(formula, data=df, return_type='dataframe')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that with `return_type='dataframe,'` Patsy's `.dmatrices()` function returns two Pandas DataFrames â€” one for the target and one for the design matrix. \n",
    "\n",
    "You'll also notice that it creates an intercept column by default. **If you do not want it to create an intercept column, add a -1 to the formula string.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula = 'CRIM ~ TAX + AGE + ZN -1'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then feed these matrices into statsmodels or scikit-learn. It is generally a good practice to convert your target matrix into a 1-D vector, especially when using scikit-learn.\n",
    "\n",
    "> **Tip:** The `.ravel()` function for NumPy arrays will \"unravel\" a multidimensional matrix into a one-dimensional vector of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
