{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> **Jupyter slideshow:** This notebook can be displayed as slides. To view it as a slideshow in your browser, type the following in the console:\n",
    "\n",
    "\n",
    "> `> jupyter nbconvert [this_notebook.ipynb] --to slides --post serve`\n",
    "\n",
    "\n",
    "> To toggle off the slideshow cell formatting, click the `CellToolbar` button, then `View --> Cell Toolbar --> None`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Introduction to DBSCAN\n",
    "\n",
    "_Authors: Joseph Nelson (DC), Alexander Combs(NYC)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"learning-objectives\"></a>\n",
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "\n",
    "After this lesson, you will be able to:\n",
    "\n",
    "- Introduce the DBSCAN algorithm.\n",
    "- Explain how DBSCAN works.\n",
    "- Compare DBSCAN to k-means and hierarchical clustering.\n",
    "- See DBSCAN in scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lesson Guide\n",
    "- [Review of Clustering](#review-of-clustering)\n",
    "\t- [K-Means](#k-means)\n",
    "\t- [Hierarchical Clustering](#hierarchical-clustering)\n",
    "- [What is DBSCAN?](#what-is-dbscan)\n",
    "- [How Does DBSCAN Work?](#how-does-dbscan-work)\n",
    "\t- [The Parameters](#the-parameters)\n",
    "\t- [The DBSCAN Algorithm](#the-dbscan-algorithm)\n",
    "\t- [DBSCAN Algorithm in Words/Review of Concept](#dbscan-algorithm-in-wordsreview-of-concept)\n",
    "\t- [Algorithm Visualization](#algorithm-visualization)\n",
    "- [How Does DBSCAN Compare to K-Means and Hierarchical Clustering?](#how-does-dbscan-compare-to-k-means-and-hierarchical-clustering)\n",
    "\t- [Pros and Cons](#pros-and-cons)\n",
    "- [How Do We Implement DBSCAN?](#how-do-we-implement-dbscan)\n",
    "\t- [Key Outputs](#key-outputs)\n",
    "- [How Do You Know What Makes for Good Estimates of Epsilon and Minimum Points?](#how-do-you-know-what-good-estimates-of-epsilon-and-min-pts-are)\n",
    "- [Additional Resources](#additional-resources)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"review-of-clustering\"></a>\n",
    "## Review of Clustering\n",
    "---\n",
    "\n",
    "- Clustering is an unsupervised learning technique we employ to group similar data points together.\n",
    "- Remember that, with unsupervised learning, there is no clear objective, no “right answer” (it's hard to tell how we’re doing), and no response variable, just observations with features (and labeled data aren't required).\n",
    "\n",
    "![](./assets/images/clusters.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"k-means\"></a>\n",
    "### K-Means\n",
    "![](./assets/images/Kmeans_animation.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Pros:**\n",
    "- Easy to implement, even on relatively large data sets (~$O(n)$).\n",
    "- Usually has decent results.\n",
    "\n",
    "**Cons:**\n",
    "- Requires an arbitrary `k`.\n",
    "- Sensitive to outliers (k-medians is more robust).\n",
    "- Lacks repeatability with random initial centroids (but can be seeded).\n",
    "- Works best if data conform to circular -> spherical -> hyperspherical shapes (n.b., using means).\n",
    "- Works best with similar density clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"hierarchical-clustering\"></a>\n",
    "### Hierarchical Clustering\n",
    "\n",
    "![](./assets/images/agglomerative-clustering.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Pros:**\n",
    "- No need to pick an explicit `k` (but we do need to pick a split point).\n",
    "- Repeatability/deterministic model (we'll always get the same clusters).\n",
    "- Can dial cluster levels at will.\n",
    "    \n",
    "**Cons:**\n",
    "- Runs in $~O(n^2)$ time, so it must be a relatively small data set.\n",
    "- Requires use to select a linkage method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"what-is-dbscan\"></a>\n",
    "## What is DBSCAN?\n",
    "---\n",
    "\n",
    "- DBSCAN: Density-based spatial clustering of applications with noise.\n",
    "- For DBSCAN, clusters of high density are separated by clusters of low density.\n",
    "- DBSCAN is the most widely used and applicable clustering algorithm.\n",
    "    - It takes a minimum predefined input and can discover clusters of any shape, not just the sphere-like clusters that k-means often computes. This way, we can discover less predefined patterns and glean some more useful insights.\n",
    "    \n",
    "**Why density?**\n",
    "\n",
    "Because DBSCAN uses a neighbor-based polling approach. It's ideal for clusters that have similar variance.\n",
    "\n",
    "**Why noise?**\n",
    "\n",
    "Because not every point will be associated with a cluster. Some are left as outlier points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"how-does-dbscan-work\"></a>\n",
    "## How Does DBSCAN Work?\n",
    "---\n",
    "\n",
    "- DBSCAN is a density-based clustering algorithm, meaning that the algorithm finds clusters by seeking out areas of the data set that have the highest density of data points.\n",
    "- Unlike in our previous examples, after you apply DBSCAN, there may be data points that aren't assigned to any cluster at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"the-parameters\"></a>\n",
    "### The Parameters\n",
    "When we use DBSCAN, it requires two input parameters: \n",
    "\n",
    "**Minimum points**: The minimum number of points required to form a cluster.\n",
    "\n",
    "**Epsilon**: The maximum distance that a point can be from the polling point in order to be recruited to the cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"the-dbscan-algorithm\"></a>\n",
    "<a id=\"the-dbscan-algorithm\"></a>\n",
    "### The DBSCAN Algorithm\n",
    "1) Choose an `epsilon` and `min_samples`.\n",
    "2) Pick an arbitrary point and check if there are at least `min_samples` points within distance `epsilon`.\n",
    "    - If yes, add those points to the cluster and check each of the new points.\n",
    "    - If no, choose another arbitrary point to start a new cluster.\n",
    "3) Stop once all of the points have been checked.\n",
    "\n",
    "![](./assets/images/dbscan.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"dbscan-algorithm-in-wordsreview-of-concept\"></a>\n",
    "<a id=\"dbscan-algorithm-in-wordsreview-of-concept\"></a>\n",
    "### DBSCAN Algorithm in Words/Review of Concept:\n",
    "\n",
    "DBSCAN will take the epsilon and minimum points we provided it and cluster all of\n",
    "the points in a neighborhood, first passing the minimum points requirement and\n",
    "then clustering each of the points within epsilon distance to form the clusters.\n",
    "\n",
    "Once one cluster is formed, the algorithm then moves to a new data point and\n",
    "seeks to find related points to form yet another cluster. This will continue until\n",
    "DBSCAN simply runs out of points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"algorithm-visualization\"></a>\n",
    "<a id=\"algorithm-visualization\"></a>\n",
    "### Algorithm Visualization\n",
    "- http://www.naftaliharris.com/blog/visualizing-dbscan-clustering/\n",
    "- Let’s play with this a bit.\n",
    "- Independently, select the “pimpled smiley” distribution of points. \n",
    "    - What is an optimal epsilon? \n",
    "    - What about minimum number of points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"how-does-dbscan-compare-to-k-means-and-hierarchical-clustering\"></a>\n",
    "## How Does DBSCAN Compare to K-Means and Hierarchical Clustering?\n",
    "---\n",
    "\n",
    "- While k-means can be thought of as a \"general\" clustering approach, DBSCAN performs especially well with unevenly distributed, non-linear clusters.\n",
    "- The fundamental difference with DBSCAN lies in the fact that it’s density based, as opposed to k-means, which calculates clusters based on distance from a central point, or hierarchical clustering.\n",
    "- By choosing too few points for DBSCAN (i.e., less than two), we'll effectively get a straight line if we connect the points, just like linkage clustering.\n",
    "\n",
    "> *Note:* If you set the criteria for minimum points too low with DBSCAN (less than two), it gives you essentially the same result as hierarchical clustering. To diversify the DBSCAN, we must provide it with a significant amount of points to form a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"pros-and-cons\"></a>\n",
    "### Pros and Cons\n",
    "\n",
    "DBSCAN can be useful when we have a lot of dense data. If we used k-means on this data, the algorithm would effectively give us one large cluster. However, with DBSCAN, we can actually break down this cluster into smaller groups to see its attributes.\n",
    "\n",
    "- **Advantages:**\n",
    "    - Clusters can be any size or shape.\n",
    "    - No need to choose the number of clusters.\n",
    "    \n",
    "\n",
    "- **Disadvantages:**\n",
    "    - More parameters to tune.\n",
    "    - Doesn’t work with clusters of varying density.\n",
    "    - Note: Not every point is assigned to a cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"how-do-we-implement-dbscan\"></a>\n",
    "## How Do We Implement DBSCAN?\n",
    "---\n",
    "\n",
    "To implement DBSCAN in Python, we first import it from scikit-learn:\n",
    "\n",
    "```Python\n",
    "from sklearn.cluster import DBSCAN\n",
    "```\n",
    "Next, assuming that we're using the classic iris data set, we define `x` as the data\n",
    "and `y` as the class variables:\n",
    "\n",
    "```Python \n",
    "X, y = iris.data, iris.target\n",
    "```\n",
    "Next, we call DBSCAN from scikit-learn:\n",
    "\n",
    "```Python\n",
    "db = DBSCAN(eps=0.3, min_samples=10).fit(X)\n",
    "```\n",
    "\n",
    "**Given the input above, what have we said about our clusters?**\n",
    "\n",
    "- Here, we've set `epsilon` to a standard value of `.3`, set the minimum number of points at `10`, and then fit the model to our data, `x`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"key-outputs\"></a>\n",
    "<a id=\"key-outputs\"></a>\n",
    "### Key Outputs\n",
    "\n",
    "- The DBSCAN algorithm in Python returns two items — the core samples and the labels. The core samples are the points that the algorithm finds initially and searches around to form the cluster, while the labels are simply the cluster labels.\n",
    "\n",
    "**Check: How many labels should we expect to receive?**\n",
    "\n",
    "```Python\n",
    "core_samples = db.core_sample_indices_\n",
    "labels = db.labels_\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"how-do-you-know-what-good-estimates-of-epsilon-and-min-pts-are\"></a>\n",
    "## How Do You Know What Makes for Good Estimates of Epsilon and Minimum Points?\n",
    "---\n",
    "A general rule when choosing the minimum points: You should always aim to have the **minimum number of points be greater or equal to the amount of dimensions in your data, plus one**. This will typically give the algorithm a good estimation of how to evaluate the clusters. \n",
    "\n",
    "Estimating epsilon is a bit trickier. One option is to use a method called the k-distance, which can help visualize the best epsilon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"additional-resources\"></a>\n",
    "<a id=\"additional-resources\"></a>\n",
    "## Additional Resources\n",
    "\n",
    "- DBSCAN documentation: http://scikitlearn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
