{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis With SpaCy and VADER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is Sentiment Analysis?\n",
    "#  \n",
    "#  \n",
    "#  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## SpaCy and Part of Speech (PoS)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse a single quote.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = u\"this is a very nice sentence about football and food\"\n",
    "sentence_parsed = en_nlp(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_parsed) # number of words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "this"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_parsed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentence_parsed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_parsed.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this DET\n",
      "is VERB\n",
      "a DET\n",
      "very ADV\n",
      "nice ADJ\n",
      "sentence NOUN\n",
      "about ADP\n",
      "football NOUN\n",
      "and CCONJ\n",
      "food NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in sentence_parsed:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 2, 'VERB': 1, 'ADV': 1, 'ADJ': 1, 'NOUN': 3, 'ADP': 1, 'CCONJ': 1}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_counts = {}\n",
    "for token in sentence_parsed:\n",
    "    pos = token.pos_\n",
    "    pos_counts[pos] = pos_counts.get(pos,0) + 1   \n",
    "pos_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DET': 0.2,\n",
       " 'VERB': 0.1,\n",
       " 'ADV': 0.1,\n",
       " 'ADJ': 0.1,\n",
       " 'NOUN': 0.3,\n",
       " 'ADP': 0.1,\n",
       " 'CCONJ': 0.1}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_perc = {}\n",
    "for k,v in pos_counts.items():\n",
    "    pos_perc [k] = 1.*v/len(sentence_parsed) \n",
    "pos_perc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Those are new features you can use!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  \n",
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>154020</th>\n",
       "      <td>VERB</td>\n",
       "      <td>take_after</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>0.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105183</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>postmodernism</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73031</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>herniated_disc</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49492</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>demonism</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77772</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>interpol</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102140</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>phospholipid</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30715</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>basinful</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134917</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>vocaliser</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95153</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>nonmalignant_tumor</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3866</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>circumstantial</td>\n",
       "      <td>0.1250</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos                word  pos_score  neg_score\n",
       "154020  VERB          take_after     0.1875     0.0625\n",
       "105183  NOUN       postmodernism     0.0000     0.0000\n",
       "73031   NOUN      herniated_disc     0.0000     0.0000\n",
       "49492   NOUN            demonism     0.0000     0.0000\n",
       "77772   NOUN            interpol     0.0000     0.0000\n",
       "102140  NOUN        phospholipid     0.0000     0.0000\n",
       "30715   NOUN            basinful     0.0000     0.0000\n",
       "134917  NOUN           vocaliser     0.0000     0.0000\n",
       "95153   NOUN  nonmalignant_tumor     0.0000     0.1250\n",
       "3866     ADJ      circumstantial     0.1250     0.0000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sen = pd.read_csv('datasets/sentiment_words_simple.csv')\n",
    "sen['pos'] = sen['pos'].str.upper()\n",
    "\n",
    "sen.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define positive-negative\n",
    "sen['pos_vs_neg'] = sen['pos_score'] - sen['neg_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>pos_vs_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116721</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>sentence</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos      word  pos_score  neg_score  pos_vs_neg\n",
       "116721  NOUN  sentence        0.0        0.0         0.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example 1\n",
    "sen[(sen['word']=='sentence') & (sen['pos']=='NOUN')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can get a score for each word and average the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very ADV 0.125\n",
      "nice ADJ 0.5750000000000001\n",
      "sentence NOUN 0.0\n",
      "football NOUN 0.0\n",
      "food NOUN -0.0416666666667\n",
      "Average sentiment: 0.13166666666666\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sentiments = []\n",
    "for token in sentence_parsed:\n",
    "    score = sen[(sen['word']==str(token)) & (sen['pos']==str(token.pos_))]['pos_vs_neg'].values\n",
    "    if len(score)>0:\n",
    "        print(token, token.pos_, score[0])\n",
    "        sentiments.append(score[0])\n",
    "print('Average sentiment: {}'.format(np.mean(sentiments)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most-obj'></a>\n",
    "#  \n",
    "#  \n",
    "#  \n",
    "## Objective and Subjective\n",
    "---\n",
    "\n",
    "Objective = 1 - (positive+negative)  \n",
    "\n",
    "\"terrible\":\n",
    "    * positve = 0.0\n",
    "    * negative = 0.8\n",
    "    * objective = 0.2\n",
    "    \n",
    "\"very\":\n",
    "    * positve = 0.7\n",
    "    * negative = 0.0\n",
    "    * objective = 0.3\n",
    "    \n",
    "\"room\":\n",
    "    * positve = 0.02\n",
    "    * negative = 0.03\n",
    "    * objective = 0.95\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "#  \n",
    "\n",
    "## Sentiment Scores with VADER Library\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vaderSentiment\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/9e/c53e1fc61aac5ee490a6ac5e21b1ac04e55a7c2aba647bb8411c9aadf24e/vaderSentiment-3.2.1-py2.py3-none-any.whl (125kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 823kB/s ta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: vaderSentiment\n",
      "Successfully installed vaderSentiment-3.2.1\n"
     ]
    }
   ],
   "source": [
    "#!pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pip install vaderSentiment.\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.',\n",
    "            'Delivers guilt-free escapism about pretty people having wicked-hot fun in pretty places.',\n",
    "            'Brian De Palma take on Tom Wolfe The Bonfire of the Vanities is a misfire of inanities.',\n",
    "            'I hated this movie. Hated hated hated hated hated this movie. Hated it.']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.\n",
      "{'neg': 0.321, 'neu': 0.526, 'pos': 0.153, 'compound': -0.5434}\n",
      "\n",
      "Delivers guilt-free escapism about pretty people having wicked-hot fun in pretty places.\n",
      "{'neg': 0.0, 'neu': 0.481, 'pos': 0.519, 'compound': 0.8658}\n",
      "\n",
      "Brian De Palma take on Tom Wolfe The Bonfire of the Vanities is a misfire of inanities.\n",
      "{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "\n",
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "{'neg': 0.855, 'neu': 0.145, 'pos': 0.0, 'compound': -0.9854}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(sentence)\n",
    "    print(vs)\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
