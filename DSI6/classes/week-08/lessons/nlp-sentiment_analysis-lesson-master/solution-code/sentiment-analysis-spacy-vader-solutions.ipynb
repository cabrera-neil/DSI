{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Sentiment Analysis of Movie Reviews with Spacy and VADER\n",
    "\n",
    "_Authors: Kiefer Katovich (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "- Understand the goal of basic sentiment analysis.\n",
    "- Calculate sentiment scores manually using a reviews dataset and scores tagged by word.\n",
    "- Practice using the spacy parser to get out part of speech tags from text.\n",
    "- Fit a model using sentiment and grammar features.\n",
    "- Use the VADER sentiment analyzer to get out more accurate sentiment scores and compare the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [Introduction to sentiment analysis](#intro)\n",
    "- [Load the word sentiment dataset](#load-sen)\n",
    "    - [Engineer objectivity and positive difference scores](#adj-scores)\n",
    "    - [Put scores in a part of speech dictionary](#pos-dict)\n",
    "- [Load the rotten tomatoes review dataset](#rt-reviews)\n",
    "    - [Restrict reviews to valid lengths and ratings](#subset)\n",
    "- [Import spacy](#spacy)\n",
    "    - [Parse all the quotes using spacy's multithreaded parser](#multi)\n",
    "- [Part of speech features](#pos-features)\n",
    "- [Assign sentiment scores](#assign)\n",
    "- [Print out the most positive and most negative reviews](#print-most)\n",
    "- [Print out the most objective and most subjective reviews](#print-most-obj)\n",
    "- [Build a model to classify fresh vs. rotten with the sentiment and grammar features](#model)\n",
    "- [User the VADER library to get better sentiment scores](#vader)\n",
    "    - [Build a model using the VADER sentiment features](#vader-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "\n",
    "## Introduction to sentiment analysis\n",
    "---\n",
    "\n",
    "Sentiment analysis is one of the most popular topics in NLP. Most commonly it is the quantification of text into valence and subjectivity scores.\n",
    "\n",
    "First we will load in a dataset of pre-coded sentiment scores for positivity and negativity on words. These words are also tagged with their part of speech in the sentence. We can use these valence scores to evaluate the sentiment of rottentomatoes movie reviews. Many packages such as TextBlob come pre-packaged with sentiment scores for words after parsing text, but doing the sentiment parsing manually will show you how it can be done without any \"magic\".\n",
    "\n",
    "We will also explore a more advanced sentiment analysis library in python: [VADER](https://github.com/cjhutto/vaderSentiment). We can parse the sentiment of the movie reviews using this package and compare it to our more basic method.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='load-sen'></a>\n",
    "\n",
    "## Load the word sentiment dataset\n",
    "---\n",
    "\n",
    "Below we will load in some pre-tagged positive and negative valence scores for a dictionary of words. Each row of the dataset contains the part of speech, the word, the positive score, and the negative score for the word. A word may appear more than once if it can appear with different part of speech tags. \n",
    "\n",
    "These scores are designed so that we can also derive the *objectivity score* of the word from the positive and negative scores.\n",
    "\n",
    "Objectivity is calculated: \n",
    "\n",
    "    1. - (positive_score + negative_score)\n",
    "\n",
    "Thus if a score has zero positive score and negative score it is completely objective. If a score has, for example, 0.5 positive and 0.5 negative, it may not be any more positive than negative but we can tell that it is subjective (objectivity = 0.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen = pd.read_csv('../datasets/sentiment_words_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adj</td>\n",
       "      <td>.22_calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adj</td>\n",
       "      <td>.38-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score\n",
       "0  adj  .22-caliber        0.0        0.0\n",
       "1  adj  .22-calibre        0.0        0.0\n",
       "2  adj  .22_caliber        0.0        0.0\n",
       "3  adj  .22_calibre        0.0        0.0\n",
       "4  adj  .38-caliber        0.0        0.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make the part of speech tags uppercase (this will come in handy later when we use Spacy).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen.pos = sen.pos.map(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='adj-scores'></a>\n",
    "\n",
    "### Engineer objectivity and positive difference scores\n",
    "\n",
    "Since subjective vs. objective is embedded in the positive and negative scores, we should extract this and convert the positive and negative into a relative difference scores.\n",
    "\n",
    "**Calculate two new scores:**\n",
    "\n",
    "    objectivity = 1. - (pos_score + neg_score)\n",
    "    pos_vs_neg = pos_score - neg_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen['objectivity'] = 1. - (sen.pos_score + sen.neg_score)\n",
    "sen['pos_vs_neg'] = sen.pos_score - sen.neg_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "      <th>objectivity</th>\n",
       "      <th>pos_vs_neg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22-calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22_caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.22_calibre</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>.38-caliber</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos         word  pos_score  neg_score  objectivity  pos_vs_neg\n",
       "0  ADJ  .22-caliber        0.0        0.0          1.0         0.0\n",
       "1  ADJ  .22-calibre        0.0        0.0          1.0         0.0\n",
       "2  ADJ  .22_caliber        0.0        0.0          1.0         0.0\n",
       "3  ADJ  .22_calibre        0.0        0.0          1.0         0.0\n",
       "4  ADJ  .38-caliber        0.0        0.0          1.0         0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-dict'></a>\n",
    "\n",
    "### Put scores in a part of speech dictionary\n",
    "\n",
    "The dictionary format of the data will be much easier to index using our parsing functions later on. Create a dictionary where the keys are the four part of speech tags:\n",
    "\n",
    "    ADJ\n",
    "    NOUN\n",
    "    VERB\n",
    "    ADV\n",
    "\n",
    "For each key, store a dictionary that contains all of the words for that part of speech with their objectivity and positive vs. negative scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sen_dict = {'ADJ':{},'NOUN':{},'VERB':{},'ADV':{}}\n",
    "\n",
    "for i, row in enumerate(sen.itertuples()):\n",
    "#     if (i % 10000) == 0:\n",
    "#         print(i)\n",
    "    sen_dict[row[1]][row[2]] = {'objectivity':row[5], 'pos_vs_neg':row[6]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rt-reviews'></a>\n",
    "\n",
    "## Load the rotten tomatoes reviews dataset\n",
    "\n",
    "---\n",
    "\n",
    "This dataset has:\n",
    "    \n",
    "    critic: critic's name\n",
    "    fresh: fresh vs. rotten rating\n",
    "    imdb: code for imdb\n",
    "    publication: where the review was published\n",
    "    quote: the review snippet\n",
    "    review_date: date of review\n",
    "    rtid: rottentomatoes id\n",
    "    title: name of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = pd.read_csv('../datasets/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams  fresh  114709.0        Time Out   \n",
       "1     Richard Corliss  fresh  114709.0   TIME Magazine   \n",
       "2         David Ansen  fresh  114709.0        Newsweek   \n",
       "3       Leonard Klady  fresh  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum  fresh  114709.0  Chicago Reader   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  \n",
       "2  Toy story  \n",
       "3  Toy story  \n",
       "4  Toy story  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='subset'></a>\n",
    "\n",
    "### Restrict data to reviews with valid ratings and reviews over 10 words long\n",
    "\n",
    "Also clean up the reviews, making a column with the case and punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt = rt[rt.fresh.isin(['fresh','rotten'])]\n",
    "rt.fresh = rt.fresh.map(lambda x: 1 if x == 'fresh' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215, 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt['quote_len'] = rt.quote.map(lambda x: len(x.split()))\n",
    "rt = rt[rt.quote_len > 10]\n",
    "rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "rt['qt'] = rt.quote.map(lambda x: ''.join([y for y in list(x.lower()) if y in string.ascii_lowercase+\" -'\"]))\n",
    "rt['qt'] = rt['qt'].map(lambda x: x.replace('-',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2458</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>1</td>\n",
       "      <td>107614.0</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>In terms of plot, the film is rather feeble, b...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>10997.0</td>\n",
       "      <td>Mrs. Doubtfire</td>\n",
       "      <td>37</td>\n",
       "      <td>in terms of plot the film is rather feeble but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12576</th>\n",
       "      <td>Robert Horton</td>\n",
       "      <td>0</td>\n",
       "      <td>190641.0</td>\n",
       "      <td>Film.com</td>\n",
       "      <td>There isn't a moment of wonder or poetry in it...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>9629.0</td>\n",
       "      <td>Pokémon: The First Movie</td>\n",
       "      <td>14</td>\n",
       "      <td>there isn't a moment of wonder or poetry in it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4900</th>\n",
       "      <td>Desson Thomson</td>\n",
       "      <td>1</td>\n",
       "      <td>91288.0</td>\n",
       "      <td>Washington Post</td>\n",
       "      <td>You may also become permanently sick of goats....</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>10960.0</td>\n",
       "      <td>Jean de Florette</td>\n",
       "      <td>32</td>\n",
       "      <td>you may also become permanently sick of goats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>James Berardinelli</td>\n",
       "      <td>1</td>\n",
       "      <td>114558.0</td>\n",
       "      <td>ReelViews</td>\n",
       "      <td>It's big, explosive entertainment and, althoug...</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>13697.0</td>\n",
       "      <td>Strange Days</td>\n",
       "      <td>22</td>\n",
       "      <td>it's big explosive entertainment and although ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11301</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>72684.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>The constant array of waxworks figures against...</td>\n",
       "      <td>2006-01-26</td>\n",
       "      <td>11717.0</td>\n",
       "      <td>Barry Lyndon</td>\n",
       "      <td>14</td>\n",
       "      <td>the constant array of waxworks figures against...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   critic  fresh      imdb      publication  \\\n",
       "2458   James Berardinelli      1  107614.0        ReelViews   \n",
       "12576       Robert Horton      0  190641.0         Film.com   \n",
       "4900       Desson Thomson      1   91288.0  Washington Post   \n",
       "1154   James Berardinelli      1  114558.0        ReelViews   \n",
       "11301                 NaN      0   72684.0         Time Out   \n",
       "\n",
       "                                                   quote review_date     rtid  \\\n",
       "2458   In terms of plot, the film is rather feeble, b...  2000-01-01  10997.0   \n",
       "12576  There isn't a moment of wonder or poetry in it...  2000-01-01   9629.0   \n",
       "4900   You may also become permanently sick of goats....  2000-01-01  10960.0   \n",
       "1154   It's big, explosive entertainment and, althoug...  2000-01-01  13697.0   \n",
       "11301  The constant array of waxworks figures against...  2006-01-26  11717.0   \n",
       "\n",
       "                          title  quote_len  \\\n",
       "2458             Mrs. Doubtfire         37   \n",
       "12576  Pokémon: The First Movie         14   \n",
       "4900           Jean de Florette         32   \n",
       "1154               Strange Days         22   \n",
       "11301              Barry Lyndon         14   \n",
       "\n",
       "                                                      qt  \n",
       "2458   in terms of plot the film is rather feeble but...  \n",
       "12576  there isn't a moment of wonder or poetry in it...  \n",
       "4900   you may also become permanently sick of goats ...  \n",
       "1154   it's big explosive entertainment and although ...  \n",
       "11301  the constant array of waxworks figures against...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='spacy'></a>\n",
    "\n",
    "## Import spacy\n",
    "\n",
    "---\n",
    "\n",
    "The spacy package is the current gold standard for parsing the grammatical structure of text (aside from neural network architectures). We are going to use it to find the part of speech tags for the review words. \n",
    "\n",
    "Once we have parsed the tags with spacy, we can assign objectivity and valence scores by finding the match in our sentiment dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parse a single quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = en_nlp(rt.qt.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "so ingenious in concept design and execution that you could watch it on a postage stamp sized screen and still be engulfed by its charm"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "concept"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can get out single words with indexing:\n",
    "tmp[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Print out the part of speech tags for each word in the quote:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "so ADV\n",
      "ingenious ADJ\n",
      "in ADP\n",
      "concept NOUN\n",
      "design NOUN\n",
      "and CCONJ\n",
      "execution NOUN\n",
      "that ADP\n",
      "you PRON\n",
      "could VERB\n",
      "watch VERB\n",
      "it PRON\n",
      "on ADP\n",
      "a DET\n",
      "postage NOUN\n",
      "stamp NOUN\n",
      "sized ADJ\n",
      "screen NOUN\n",
      "and CCONJ\n",
      "still ADV\n",
      "be VERB\n",
      "engulfed VERB\n",
      "by ADP\n",
      "its ADJ\n",
      "charm NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in tmp:\n",
    "    print(token,token.pos_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='multi'></a>\n",
    "### Parse all the quotes using spacy's multithreaded parser\n",
    "\n",
    "Parsing a lot of text can take quite awhile. Luckily spacy comes with multithreading functionality to speed up the process considerably. Below is code that will parse the quotes across multiple threads and assign them to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "parsed_quotes = []\n",
    "for i, parsed in enumerate(en_nlp.pipe(rt.qt.values, batch_size=50, n_threads=4)):\n",
    "    assert parsed.is_parsed\n",
    "    if (i % 1000) == 0:\n",
    "        print(i)\n",
    "    parsed_quotes.append(parsed)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pos-features'></a>\n",
    "\n",
    "## Create features with part of speech proportions\n",
    "\n",
    "---\n",
    "\n",
    "With our spacy parsed reviews, we have a lot of feature engineering potential even before we get to sentiment. Something simple we could do is calculate the proportion of words in the quote that have each part of speech tag. We can try using these as predictors in a model later.\n",
    "\n",
    "**Find all the unique part of speech categories in the reviews.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ADJ' 'ADP' 'ADV' 'CCONJ' 'DET' 'INTJ' 'NOUN' 'NUM' 'PART' 'PRON' 'PROPN'\n",
      " 'PUNCT' 'SPACE' 'SYM' 'VERB' 'X']\n"
     ]
    }
   ],
   "source": [
    "unique_pos = []\n",
    "for parsed in parsed_quotes:\n",
    "    unique_pos.extend([t.pos_ for t in parsed])\n",
    "unique_pos = np.unique(unique_pos)\n",
    "print(unique_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the proportion columns for each part of speech.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pos in unique_pos:\n",
    "    rt[pos+'_prop'] = 0.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate through the reviews and calculate the proportions of each part of speech tag.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 100 200 300 400 500 600 700 800 900 1000 1100 1200 1300 1400 1500 1600 1700 1800 1900 2000 2100 2200 2300 2400 2500 2600 2700 2800 2900 3000 3100 3200 3300 3400 3500 3600 3700 3800 3900 4000 4100 4200 4300 4400 4500 4600 4700 4800 4900 5000 5100 5200 5300 5400 5500 5600 5700 5800 5900 6000 6100 6200 6300 6400 6500 6600 6700 6800 6900 7000 7100 7200 7300 7400 7500 7600 7700 7800 7900 8000 8100 8200 8300 8400 8500 8600 8700 8800 8900 9000 9100 9200 9300 9400 9500 9600 9700 9800 9900 10000 10100 10200 10300 10400 10500 10600 10700 10800 10900 11000 11100 11200 "
     ]
    }
   ],
   "source": [
    "rt = rt.reset_index(drop=True)\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 100) == 0:\n",
    "        print(i, end=' ')\n",
    "    parsed_len = len(parsed)\n",
    "    for pos in unique_pos:\n",
    "        count = len([x for x in parsed if x.pos_ == pos])\n",
    "        rt.loc[i, pos+'_prop'] = float(count)/parsed_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='assign'></a>\n",
    "\n",
    "## Assign sentiment scores\n",
    "---\n",
    "\n",
    "We will now use the parsed reviews and the sentiment dataset to assign the average objectivity and positive vs. negative scores.\n",
    "\n",
    "If a word cannot be found in the dataset we can ignore it. If a review has no words that match something in our dataset, will can assign overall neutral scores of `objectivity = 1` and `pos_vs_neg = 0`.\n",
    "\n",
    "There are definitely problems with this approach, but for now we can keep it \"dumb\" and see if things improve when we use the VADER analyzer later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "def scorer(parsed):\n",
    "    obj_scores, pvn_scores = [], []\n",
    "    for token in [t for t in parsed if t.pos_ in ['NOUN','VERB','ADV','ADJ']]:\n",
    "        try:\n",
    "            obj_scores.append(sen_dict[token.pos_][str(token)]['objectivity'])\n",
    "            pvn_scores.append(sen_dict[token.pos_][str(token)]['pos_vs_neg'])\n",
    "        except:\n",
    "            pass\n",
    "    if len(obj_scores) == 0:\n",
    "        obj_scores = [1.]\n",
    "    if len(pvn_scores) == 0:\n",
    "        pvn_scores = [0.]\n",
    "    return [obj_scores, pvn_scores]\n",
    "\n",
    "\n",
    "scores = []\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 1000) == 0:\n",
    "        print(i)\n",
    "    scores.append(scorer(parsed))\n",
    "    \n",
    "rt['objectivity_avg'] = [np.mean(x[0]) for x in scores]\n",
    "rt['pos_vs_neg_avg'] = [np.mean(x[1]) for x in scores]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most'></a>\n",
    "## Print out the most positive and most negative reviews\n",
    "---\n",
    "\n",
    "Now that we have the average valence for reviews, try printing out the top 10 most positive and top 10 most negative reviews to visually verify that our approach makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you love vintage Woody Allen, you'll like the nouveau Rob Reiner.\n",
      "--------------------------------------------------------------------------------\n",
      "As bustling and impassioned as the best Sturges and Capra movies.\n",
      "--------------------------------------------------------------------------------\n",
      "Hanks is superb, reemploying the childlike presence he brought to Big.\n",
      "--------------------------------------------------------------------------------\n",
      "Streep (the best thing she has done in ages) carries it along.\n",
      "--------------------------------------------------------------------------------\n",
      "High Noon combines its points about good citizenship with some excellent picturemaking.\n",
      "--------------------------------------------------------------------------------\n",
      "Paths of Glory is all about that greatest of all movie subjects: power.\n",
      "--------------------------------------------------------------------------------\n",
      "Improbabilities and all, Simpatico still boasts wonderful scenes and a cast that is truly superb.\n",
      "--------------------------------------------------------------------------------\n",
      "From Russia with Love is a preposterous, skillful slab of hardhitting, sexy hokum.\n",
      "--------------------------------------------------------------------------------\n",
      "Although the characters are basically stereotypes, they are lent the gift of life by a superlative cast.\n",
      "--------------------------------------------------------------------------------\n",
      "Succeeds, in part, because the film is as non-judgmental as the famed sex researcher himself.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('pos_vs_neg_avg', ascending=False, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print(quote)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unoriginal and insulting, 3 Strikes goes down without scoring a single chuckle.\n",
      "--------------------------------------------------------------------------------\n",
      "Brooding, somber film is ragged around the edges and not without problematic aspects.\n",
      "--------------------------------------------------------------------------------\n",
      "Its tone is never exactly comedic and its horrific touches are more disgusting than scary.\n",
      "--------------------------------------------------------------------------------\n",
      "It's a disturbing, hopeless, irredeemable series of images that will scar you if you wander into it unprepared.\n",
      "--------------------------------------------------------------------------------\n",
      "...Liar Liar stands to make a liar out of those who predicted that Carrey's career was on the skids.\n",
      "--------------------------------------------------------------------------------\n",
      "A silly movie, with silly jokes and a silly story. But the talents at work in it are not silly.\n",
      "--------------------------------------------------------------------------------\n",
      "Likely to be disappointing to Almodovar's admirers, and inexplicable to anyone else.\n",
      "--------------------------------------------------------------------------------\n",
      "Bringing Out the Dead is stunning to look at; unfortunately, it's not terribly satisfying to watch.\n",
      "--------------------------------------------------------------------------------\n",
      "Both bleak and bleakly funny, appalling in its excesses and exhilarating in its execution.\n",
      "--------------------------------------------------------------------------------\n",
      "You may find yourself shaken -- not stirred -- by the screenwriting cruelty and cynicism behind the 16th Bond.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('pos_vs_neg_avg', ascending=True, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print(quote)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='print-most-obj'></a>\n",
    "\n",
    "## Print out the most objective and most subjective reviews\n",
    "---\n",
    "\n",
    "Do the same as above, but now sort by the objectivity. What kind of differences do you notice between these? Does our approach actually appear to capture meaningful subjectivity and objectivity in the reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One of the finest collaborations between husband and wife ever committed to film.\n",
      "--------------------------------------------------------------------------------\n",
      "Brian De Palma's take on Tom Wolfe's The Bonfire of the Vanities is a misfire of inanities.\n",
      "--------------------------------------------------------------------------------\n",
      "Barbara Stanwyck is the sexiest con woman ever captured on film.\n",
      "--------------------------------------------------------------------------------\n",
      "The Ref benefits from having actor's actors like Davis and Spacey in the leads.\n",
      "--------------------------------------------------------------------------------\n",
      "A crackling thriller that feels unusually attuned to its lowlife characters.\n",
      "--------------------------------------------------------------------------------\n",
      "Vicky Cristina Barcelona is the cinematic equivalent of a book on tape: a movie that watches itself for you and tells you what it sees.\n",
      "--------------------------------------------------------------------------------\n",
      "Dr. Dolittle runs out of ideas long before the projector runs out of film.\n",
      "--------------------------------------------------------------------------------\n",
      "Someone deserves a timeout for letting this mawkish misfire get to the screen.\n",
      "--------------------------------------------------------------------------------\n",
      "Titanic is indeed a ship of dreams. Climb aboard and bon voyage.\n",
      "--------------------------------------------------------------------------------\n",
      "Heeere's Jackie, ageless and great, before refitting himself to Western specs.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('objectivity_avg', ascending=False, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print(quote)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They keep getting worse and worse and worse . . .\n",
      "--------------------------------------------------------------------------------\n",
      "Jumps adroitly between the macho and anti-macho, the romantic and anti-romantic.\n",
      "--------------------------------------------------------------------------------\n",
      "It's grave, lumbering, arrhythmic, and bloated, an emotional hogwallow of catchpenny insights and easy sentimentality.\n",
      "--------------------------------------------------------------------------------\n",
      "If you love vintage Woody Allen, you'll like the nouveau Rob Reiner.\n",
      "--------------------------------------------------------------------------------\n",
      "I am not sure why this isn't very funny, but it's not.\n",
      "--------------------------------------------------------------------------------\n",
      "Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.\n",
      "--------------------------------------------------------------------------------\n",
      "Delivers guilt-free escapism about pretty people having wicked-hot fun in pretty places.\n",
      "--------------------------------------------------------------------------------\n",
      "In spite of its shortcomings, children love these characters and will enjoy Tigger.\n",
      "--------------------------------------------------------------------------------\n",
      "At its best when it's being lighthearted and at its weakest when it takes a halfhearted stab at semi-seriousness.\n",
      "--------------------------------------------------------------------------------\n",
      "As incoherent about its mysticism as it is about anything else.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('objectivity_avg', ascending=True, inplace=True)\n",
    "for quote in rt.quote[0:10]:\n",
    "    print(quote)\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There doesn't seem to be much signal in the objectivity score. They look pretty\n",
    "# similar to me!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='model'></a>\n",
    "\n",
    "## Build a model to classify fresh vs. rotten with the sentiment and grammar features\n",
    "\n",
    "---\n",
    "\n",
    "Let's use the features we've created to construct a Logistic Regression to predict whether a review is fresh vs. rotten. \n",
    "\n",
    "Don't forget to check the baseline score, and it's a good practice to standardize your predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6367301195070518 0.6150691038787338\n"
     ]
    }
   ],
   "source": [
    "X = rt[['objectivity_avg','pos_vs_neg_avg','quote_len']+[x for x in rt.columns if x.endswith('_prop')]]\n",
    "y = rt.fresh.values\n",
    "\n",
    "ss = StandardScaler()\n",
    "Xs = ss.fit_transform(X)\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), Xs, y, cv=10)\n",
    "print(np.mean(lr_scores), rt.fresh.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We do a bit better than the baseline using the default logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['objectivity_avg', 'pos_vs_neg_avg', 'quote_len', 'ADJ_prop',\n",
       "       'ADP_prop', 'ADV_prop', 'CCONJ_prop', 'DET_prop', 'INTJ_prop',\n",
       "       'NOUN_prop', 'NUM_prop', 'PART_prop', 'PRON_prop', 'PROPN_prop',\n",
       "       'PUNCT_prop', 'SPACE_prop', 'SYM_prop', 'VERB_prop', 'X_prop'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectivity_avg -0.131444297627609\n",
      "pos_vs_neg_avg 0.4464137790705639\n",
      "quote_len 0.09727097153371356\n",
      "ADJ_prop 0.06213084448904941\n",
      "ADP_prop 0.003694343967884319\n",
      "ADV_prop -0.09793705720106265\n",
      "CCONJ_prop 0.06760724087733976\n",
      "DET_prop -0.038602326689058074\n",
      "INTJ_prop -0.018496623504046832\n",
      "NOUN_prop 0.11570754102438945\n",
      "NUM_prop 0.025407887114821125\n",
      "PART_prop -0.06921766261357128\n",
      "PRON_prop 0.09500622741485829\n",
      "PROPN_prop 0.02207238224866559\n",
      "PUNCT_prop -0.013472040372492371\n",
      "SPACE_prop -0.0011233154043179935\n",
      "SYM_prop -0.0015272322848200398\n",
      "VERB_prop -0.1570218432085458\n",
      "X_prop 0.017936629166324103\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression().fit(Xs, y)\n",
    "for var, coef in zip(X.columns, lr.coef_[0]):\n",
    "    print(var, coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The coefficients make sense for the sentiment features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=25, class_weight=None, cv=10, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='ovr', n_jobs=1, penalty='l1', random_state=None,\n",
       "           refit=True, scoring=None, solver='liblinear', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# Try a lasso penalty\n",
    "lrcv = LogisticRegressionCV(penalty='l1', solver='liblinear', Cs=25, cv=10)\n",
    "lrcv.fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.12699201,  0.44109708,  0.09206572,  0.0489623 ,  0.        ,\n",
       "        -0.10325072,  0.06131766, -0.04171676, -0.01529365,  0.097199  ,\n",
       "         0.0183418 , -0.06937002,  0.08047236,  0.01666603, -0.01109301,\n",
       "         0.        ,  0.        , -0.16260935,  0.01268696]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looks like it still keeps a fair amount of the features.\n",
    "lrcv.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader'></a>\n",
    "\n",
    "## Use the VADER library to get better sentiment scores\n",
    "---\n",
    "\n",
    "The [VADER](https://github.com/cjhutto/vaderSentiment) package for python is a more advanced way to calculate positivity, negativity, and objectivity in our reviews. The github page describes VADER as:\n",
    "\n",
    "> VADER Sentiment Analysis. VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media, and works well on texts from other domains.\n",
    "\n",
    "You will likely need to install VADER with pip or conda. Instructions can be found on the github page. Once you have it installed you can load the `SentimentIntensityAnalyzer` and parse text.\n",
    "\n",
    "**Parse a couple of quotes with the `SentimentIntensityAnalyzer` and print out the dictionary of scores using `analyzer.polarity_scores`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They keep getting worse and worse and worse . . .\n",
      "{'neg': 0.65, 'neu': 0.35, 'pos': 0.0, 'compound': -0.8519}\n",
      "Jumps adroitly between the macho and anti-macho, the romantic and anti-romantic.\n",
      "{'neg': 0.0, 'neu': 0.787, 'pos': 0.213, 'compound': 0.4019}\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "for sentence in rt.quote.values[0:2]:\n",
    "    vs = analyzer.polarity_scores(sentence)\n",
    "    print(sentence)\n",
    "    print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that these scores look more legitimate. VADER polarity score dictionaries have 4 elements: `neg`, `pos`, `neu` and `compound`. The compound score is a single metric that represents the \"overall\" valence.\n",
    "\n",
    "**Calculate the four scores for each review and save them as features in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "rt['vader_neg'] = 0\n",
    "rt['vader_pos'] = 0\n",
    "rt['vader_neu'] = 0\n",
    "rt['vader_compound'] = 0\n",
    "\n",
    "for i, q in enumerate(rt.quote.values):\n",
    "    vs = analyzer.polarity_scores(q)\n",
    "    rt.iloc[i, -4] = vs['neg']\n",
    "    rt.iloc[i, -3] = vs['pos']\n",
    "    rt.iloc[i, -2] = vs['neu']\n",
    "    rt.iloc[i, -1] = vs['compound']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-model'></a>\n",
    "\n",
    "### Fit a model using the VADER sentiment features\n",
    "\n",
    "Does this model perform better? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.67736185 0.68092692 0.65240642 0.66755793 0.65508021 0.65151515\n",
      " 0.64795009 0.62087422 0.62410714 0.59017857]\n",
      "0.6467958507707682\n"
     ]
    }
   ],
   "source": [
    "X = rt[['vader_neg','vader_pos','vader_neu','vader_compound','quote_len']]\n",
    "y = rt.fresh.values\n",
    "\n",
    "Xs = StandardScaler().fit_transform(X)\n",
    "\n",
    "scores = cross_val_score(LogisticRegression(), Xs, y, cv=10)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "# We do slightly better. I've also left out the part of speech stuff so that has an impact too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression().fit(Xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neg -0.23561761659663846\n",
      "pos 0.32067595059188947\n",
      "neu -0.12730574331071565\n",
      "compound 0.19851782945578514\n",
      "len 0.10070925676621627\n"
     ]
    }
   ],
   "source": [
    "for c, v in zip(LogisticRegression().fit(Xs, y).coef_[0], ['neg','pos','neu','compound','len']):\n",
    "    print(v, c)\n",
    "    \n",
    "# All the coefficients make sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='vader-top'></a>\n",
    "\n",
    "### Print out the top most negative, positive, neutral, and subjective features by VADER score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "--------------------------------------------------------------------------------\n",
      "They keep getting worse and worse and worse . . .\n",
      "--------------------------------------------------------------------------------\n",
      "What's the fourth \"Die Hard\" called? I keep forgetting. \"Die Hard: With a Pension\"? \"Die Hardened Arteries\"? \"Die Laughing\"?\n",
      "--------------------------------------------------------------------------------\n",
      "A shambolic, deafening, intelligence-insulting mess, a crushing failure on almost all counts.\n",
      "--------------------------------------------------------------------------------\n",
      "So distressingly dark, grim, and cynical it's likely to make kids cry!\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neg', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print(rt['quote'].values[i])\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A truly funny, sophisticated, compassionate, mainstream Hollywood comedy about very modern homosexuality.\n",
      "--------------------------------------------------------------------------------\n",
      "Extremely handsome production values and a great supporting cast round out the virtues.\n",
      "--------------------------------------------------------------------------------\n",
      "For lovers of romantic comedies through the ages, Roman Holiday remains a favorite.\n",
      "--------------------------------------------------------------------------------\n",
      "The Karate Kid exhibits warmth and friendly, predictable humor, its greatest assets.\n",
      "--------------------------------------------------------------------------------\n",
      "Charming performances and easygoing humour are the strengths of Jones's enjoyable Oirish romp.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_pos', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print(rt['quote'].values[i])\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raoul Coutard's Techniscope cinematography contemplates an espresso, filling the screen in monumental close-up with a rotating vortex of bubbles and foam.\n",
      "--------------------------------------------------------------------------------\n",
      "This film was produced by Mr. Wilder for Allied Artists -- in black-and-white. It is a hit.\n",
      "--------------------------------------------------------------------------------\n",
      "This film, minus the deft and artistic handling of the director, Alfred Hitchcock, despite its cast and photography, would not stand up for Grade A candidacy.\n",
      "--------------------------------------------------------------------------------\n",
      "The movie is all anticlimax once we realize it's going to be about gimmicks, not characters.\n",
      "--------------------------------------------------------------------------------\n",
      "The musical numbers, actually performed by the on-screen band, are sensational.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neu', ascending=False, inplace=True)\n",
    "for i in range(5):\n",
    "    print(rt['quote'].values[i])\n",
    "    print('-'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I hated this movie. Hated hated hated hated hated this movie. Hated it.\n",
      "--------------------------------------------------------------------------------\n",
      "Welcome to Natural Born Killers, Stone's empty, manic meditation on society's glorification of violence and the ugly heroes it loves to hate.\n",
      "--------------------------------------------------------------------------------\n",
      "Branagh's lame stab at a romantic psychological thriller makes no sense.\n",
      "--------------------------------------------------------------------------------\n",
      "A truly funny, sophisticated, compassionate, mainstream Hollywood comedy about very modern homosexuality.\n",
      "--------------------------------------------------------------------------------\n",
      "Hilarious, sexy, clever, playful and as initially teasing as it is ultimately satisfying.\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "rt.sort_values('vader_neu', ascending=True, inplace=True)\n",
    "for i in range(5):\n",
    "    print(rt['quote'].values[i])\n",
    "    print('-'*80)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
