{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> **Jupyter slideshow:** This notebook can be displayed as slides. To view it as a slideshow in your browser type in the console:\n",
    "\n",
    "\n",
    "> `> jupyter nbconvert [this_notebook.ipynb] --to slides --post serve`\n",
    "\n",
    "\n",
    "> To toggle off the slideshow cell formatting, click the `CellToolbar` button, then `View --> Cell Toolbar --> None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "\n",
    "# Recommendation Engines\n",
    "\n",
    "_Author: Alex Combs (NYC) _\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"learning-objectives\"></a>\n",
    "### Learning Objectives\n",
    "*After this lesson, you will be able to:*\n",
    "- Explain what a recommendation engines is\n",
    "- Explain the math behind recommendation engines\n",
    "- Explain the types of recommendation engines and their pros and cons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lesson Guide\n",
    "- [What is a recommendation engine?](#what-is-a-recommendation-engine)\n",
    "    - [Why bother?](#why-bother)\n",
    "    - [Who uses recommendation systems?](#who-uses-recommendation-systems)\n",
    "    - [Explicit data vs Implicit data](#explicit-data-vs-implicit-data)\n",
    "\t- [Two classical recommendation methods](#two-classical-recommendation-methods)\n",
    "\n",
    "\n",
    "- [User-based Collaborative Filtering](#user-based-collaborative-filtering)\n",
    "    - [So, let's see how we construct it](#so-lets-see-how-we-construct-it)\n",
    "\t- [Formula](#formula)\n",
    "    - [Cosine similarity using sci-kit learn](#cosine-similarity-using-sci-kit-learn)\n",
    "    - [The problem with zero](#the-problem-with-zero)\n",
    "    - [Exercise: Find the similarity between X and Y and X and Z for the following.](#exercise-find-the-similarity-between-x-and-y-and-x-and-z-for-the-following)\n",
    "\n",
    "\n",
    "- [Item-based Collaborative Filtering](#item-based-collaborative-filtering)\n",
    "    - [Exercise: Center the values by row and find the cosine similarity for each row vs. row 5 (S5)](#exercise-center-the-values-by-row-and-find-the-cosine-similarity-for-each-row-vs-row--s)\n",
    "\n",
    "\n",
    "- [Content-based Filtering](#content-based-filtering)\n",
    "    - [Example](#example)\n",
    "\n",
    "\n",
    "- [Independent Exercise](#independent-exercise)\n",
    "- [Conclusion](#conclusion)\n",
    "- [Extra Practice](#extra-practice)\n",
    "- [Additional Resources](#additional-resources)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"what-is-a-recommendation-engine\"></a>\n",
    "## What is a recommendation engine?\n",
    "---\n",
    "\n",
    "At its most basic: A system designed to match users to things that they will like.\n",
    "\n",
    "- The \"things\" can be products, brands, media, or even other people. \n",
    "- Ideally, they should be things the user doesn't know about. \n",
    "- **The goal is to rank all the possible things that are available to the user and to only present the top items**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"why-bother\"></a>\n",
    "### Why bother?\n",
    "\n",
    "- 1/4 to a 1/3 of consumer choices at Amazon are driven by personalized recommendations\n",
    "- Netflix says there recommendation engine reduces churn saving the company in excess of $1 billion a year\n",
    "- Hulu [has shown](http://tech.hulu.com/blog/2011/09/19/recommendation-system.html) that showing recommended TV shows results in over 3x more clicks than only showing the most popular TV shows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<a id=\"who-uses-recommendation-systems\"></a>\n",
    "### Who uses recommendation systems?\n",
    "\n",
    "- Netflix\n",
    "- Pandora\n",
    "- Hulu\n",
    "- Tinder\n",
    "- Facebook\n",
    "- Barnes & Noble (receipts recommend other books)\n",
    "- Target (sent directed ads based on motherhood predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"the-data-for-recommendations\"></a>\n",
    "### The data for recommendations\n",
    "\n",
    "\n",
    "To make a prediction about what someone will like, we need to have data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<a id=\"explicit-data-vs-implicit-data\"></a>\n",
    "### Explicit data vs Implicit data\n",
    "\n",
    "#### Explicit\n",
    "- Explicity given/pro-actively acquired\n",
    "- Clear signals\n",
    "- Cost associated with acquisition (time/cognitive)\n",
    "- Limited and sparse data because of this\n",
    "\n",
    "\n",
    "#### Implicit\n",
    "- Provided/collected passively (digital exhaust)\n",
    "- Signals can be difficult to interpret\n",
    "- Enormous quantities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"if-you-have-the-data-you-can-build-it\"></a>\n",
    "### If you have the data, you can build it....\n",
    "\n",
    "But how?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"two-classical-recommendation-methods\"></a>\n",
    "### Two classical recommendation methods\n",
    "\n",
    "- **Similar people**\n",
    "    - If you like the same 5 movies as someone else, you'll likely enjoy other movies they like.\n",
    "    - There are two main types: (a) Find users who are similar and recommend what they like (**user-based**), or (b) recommend items that are similar to already-liked items (**item-based**).\n",
    "   \n",
    "\n",
    "- **Similar items**\n",
    "    - If you enjoy certain characteristics of movies (e.g. certain actors, genre, etc.), you'll enjoy other movies with those characteristics.\n",
    "    - Note this can easily be done using machine learning methods! Each movie can be decomposed into features. Then, for each user we compute a model -- the target can be a binary classifier (e.g. \"LIKE\"/\"DISLIKE\") or regression (e.g. star rating)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- The first is called **Collaborative Filtering**\n",
    "- The second is called **Content-based Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"user-based-collaborative-filtering\"></a>\n",
    "## User-based Collaborative Filtering\n",
    "---\n",
    "\n",
    "We'll first look at user-based filtering. The idea behind this method is finding your taste **doppelg√§nger**. This is the person who is most similar to you based upon the ratings both of you have given to a mix of products."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"so-lets-see-how-we-construct-it\"></a>\n",
    "## So, let's see how we construct it\n",
    "\n",
    "We begin with what's called a utility matrix. This is a **user** (rows) x **product** (columns) matrix.\n",
    "<img src=\"http://i.imgur.com/Ce838dV.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "***Check:*** If we want to find the most similar users, what do we need?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If we want to find the users most similar to user A, we need a similarity metric.\n",
    "\n",
    "One metric we can use is **cosine similarity**. Cosine similarity uses the cosine between two vectors to compute a scalar value that represents how closely related these vectors are. \n",
    "\n",
    "- Angle of $0^{\\circ}$ (same direction): $\\cos(0^{\\circ}) = 1$. Perfectly similar.\n",
    "- Angle of $90^{\\circ}$ (orthogonal): $\\cos(90^{\\circ}) = 0$. Perfectly dissimilar.\n",
    "- Angle of $180^{\\circ}$ (opposite direction): $\\cos(90^{\\circ}) = -1$.\n",
    "\n",
    "\n",
    "Doesn't this sound a lot like the correlation coefficient? It turns out that cosine similarity is identical to the **uncentered correlation coefficient**! As a bonus, if the points are mean-centered, then this formula also depicts the **Pearson correlation coefficient**.\n",
    "\n",
    "<a id=\"formula\"></a>\n",
    "### Formula\n",
    "You may be familiar with the Euclidean dot product formula from trigonometry:\n",
    "\n",
    "$$\\mathbf{A} \\cdot \\mathbf{B} = \\|\\mathbf{A}\\|\\|\\mathbf{B}\\|\\cos{\\theta}$$\n",
    "\n",
    "Let's rewrite it a bit to give our new similarity measure:\n",
    "\n",
    "$$similarity = \\cos{\\theta} = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{\\|\\mathbf{A}\\|\\|\\mathbf{B}\\|}$$\n",
    "\n",
    "Keep in mind that $\\frac{\\mathbf{A}}{\\|\\mathbf{A}\\|}$ is the unit vector along the direction of $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"cosine-similarity-using-sci-kit-learn\"></a>\n",
    "## Cosine similarity using sci-kit learn\n",
    "\n",
    "With that, let's calculate the cosine similarity of A against all other users. We'll start with B. We have a sparse matrix so let's just fill in 0 for the missing values.\n",
    "\n",
    "<a id=\"a-vs-b\"></a>\n",
    "### A vs B\n",
    "```python\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(np.array([4,0,5,3,5,0,0]).reshape(1,-1),\\\n",
    "np.array([0,4,0,4,0,5,0]).reshape(1,-1))\n",
    "```\n",
    " This give us cosine similarity of **.1835**\n",
    "\n",
    "This is a low rating and makes sense since they have no ratings in common.\n",
    "\n",
    "Let's run it for user A and C now.\n",
    "\n",
    "<a id=\"a-vs-c\"></a>\n",
    "### A vs C\n",
    "```python\n",
    "cosine_similarity(np.array([4,0,5,3,5,0,0]).reshape(1,-1),\\\n",
    "np.array([2,0,2,0,1,0,0]).reshape(1,-1))\n",
    "```\n",
    "\n",
    "This gives us a cosine simularity of **.8852.**\n",
    "\n",
    "#### This indicates these users are very similar. But are they?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"the-problem-with-zero\"></a>\n",
    "### The problem with zero\n",
    "\n",
    "By inputing 0 to fill the missing values, we have indicated strong negative sentiment for the missing ratings and thus agreement where there is none. We should instead represent that with a neutral value. We can do this by **mean centering** the values at zero. Let's see how that works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We add up all the ratings for user A and then divide by the total ratings. In this case that is 17/4 or 4.25. We then subtract this 4.25 from every individual rating. We then do the same for all other users, subtracting their mean ratings from each of their ratings. <br><br>That gives us the following table:\n",
    "\n",
    "<img src=\"http://i.imgur.com/QuM7xsa.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "<a id=\"a-vs-b\"></a>\n",
    "### A vs B\n",
    "```python\n",
    "cosine_similarity(np.array([-.25,0,.75,-1.25,.75,0,0])\\\n",
    ".reshape(1,-1),\\\n",
    "np.array([0,-.33,0,-.33,0,.66,0])\\\n",
    ".reshape(1,-1))\n",
    "```\n",
    "\n",
    "This new figure for this is:  **.3077**\n",
    "\n",
    "\n",
    "<a id=\"a-vs-c\"></a>\n",
    "### A vs C\n",
    "```python\n",
    "cosine_similarity(np.array([-.25,0,.75,-1.25,.75,0,0])\\\n",
    ".reshape(1,-1),\\\n",
    "np.array([.33,0,.33,0,-.66,0,0])\\\n",
    ".reshape(1,-1))\n",
    "```\n",
    "The new figure for this is: **-0.246**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"so-what-happened\"></a>\n",
    "## So what happened?\n",
    "\n",
    "So the A and B got more similar and A and C got further apart, which is what we'd hope to see. This centering process also has another benefit in that easy and hard raters are put on the same basis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"exercise-find-the-similarity-between-x-and-y-and-x-and-z-for-the-following\"></a>\n",
    "## Exercise: Find the similarity between X and Y and X and Z for the following.\n",
    "\n",
    "|User |Snarky's Potato Chips\t| SoSo Smoth Lotion\t|Duffly Beer\t|BetterTap Water\t|XXLargeLivin' Football Jersey\t|Snowy Cotton Ballas\t|Disposos Diapers|\n",
    "|:-:|---|---|---|---|---|---|---|---|\n",
    "| X| |4| | 3| | 4| |\n",
    "| Y| |3.5| | 2.5| | 4| 4|\n",
    "| Z| | 4| | 3.5| | 4.5| 4.5|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity(X, Y) = [[0.83333333]]\n",
      "similarity(Y, Z) = [[0.98473193]]\n",
      "similarity(X, Z) = [[0.73854895]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# 1. Vectorize the data\n",
    "\n",
    "X = np.array([0.0, 4.0, 3.0, 0.0, 4.0, 0.0])\n",
    "Y = np.array([0.0, 3.5, 2.5, 0.0, 4.0, 4.0])\n",
    "Z = np.array([0.0, 4.0, 3.5, 0.0, 4.5, 4.5])\n",
    "\n",
    "# 2. Mean-center\n",
    "\n",
    "X[X!=0] -= np.mean(X[X!=0])\n",
    "Y[Y!=0] -= np.mean(Y[Y!=0])\n",
    "Z[Z!=0] -= np.mean(Z[Z!=0])\n",
    "\n",
    "# 3. Cosine similarity\n",
    "\n",
    "print(\"similarity(X, Y) = \" + str(cosine_similarity(X.reshape(1,-1), Y.reshape(1,-1))))\n",
    "print(\"similarity(Y, Z) = \" + str(cosine_similarity(Y.reshape(1,-1), Z.reshape(1,-1))))\n",
    "print(\"similarity(X, Z) = \" + str(cosine_similarity(X.reshape(1,-1), Z.reshape(1,-1))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"but-how-do-we-predict-the-rating-of-an-item-for-a-user\"></a>\n",
    "## But how do we predict the rating of an item for a user?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "| User |Snarky's Potato Chips\t| SoSo Smoth Lotion\t|Duffly Beer\t|BetterTap Water |XXLargeLivin' Football Jersey\t|Snowy Cotton Ballas\t|Disposos Diapers|\n",
    "| - |:-------:| --:| --- | --- | --- | --- | --- |\n",
    "| X| &nbsp; |4  | &nbsp; | 3  | &nbsp; | 4  | &nbsp;  |\n",
    "| Y| &nbsp; |3.5| &nbsp; | 2.5| &nbsp; | 4  | 4  |\n",
    "| Z| &nbsp; |4  | &nbsp; | 3.5| &nbsp; | 4.5| 4.5|\n",
    "\n",
    "What can we predict User X will rate Disposos Diapers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next we'll find the expected rating for User X for Disposo's Diapers using the weighted results of the two closest users (we only have two here, but normally k would be selected) Y and Z.\n",
    "\n",
    "We do this by weighing each user's similarity to X and multiplying by their rating. We then divide by the sum of their similarities to arrive at our rating.\n",
    "\n",
    "For k of 2:<br>\n",
    "** (1st closest cosine sim x their product rating + 2nd closest cosine sim x their product rating) / (sum of 1st and 2nd's cosine sims) **\n",
    "\n",
    "$$\\frac{0.83333333 \\cdot (4) + 0.73854895 \\cdot (4.5)}{0.83333333 + 0.73854895} = 4.23$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Check: What might be some problems with user-based filtering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Frequently-liked items will necessarily have users who like all kinds of other items. So, recommendations based on frequently-liked items may be inaccurate.\n",
    "\n",
    "- User-based filtering also suffers from the **cold-start problem**. If a new user joins and has very few likes, then it is difficult to pair them with a similar user.\n",
    "\n",
    "- Lastly, suppose that a user with few likes adds a new like. This may significantly change the recommendations. Hence, as users add likes, the recommendations must be continually and quickly updated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In practice, there is a type of collaborative filtering that can perform much better than user-based filtering: **item-based filtering**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"item-based-collaborative-filtering\"></a>\n",
    "## Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's take a look at an example ratings table. Here we have songs on the left and users on the top.\n",
    "\n",
    "<img src=\"http://i.imgur.com/JoBHXcG.png\">\n",
    "\n",
    "In item-based filtering, we are trying to find similarities across items rather than users.<br>\n",
    "Just as in user-based filtering, we need to center our values by row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"exercise-center-the-values-by-row-and-find-the-cosine-similarity-for-each-row-vs-row--s\"></a>\n",
    "## Exercise: Center the values by row and find the cosine similarity for each row vs. row 5 (S5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The nearest songs should have been S1 and S3. To calculate the rating for our target song, S5, for U3, using a k of 2, we have the following equation:\n",
    "\n",
    "For k of 2:<br>\n",
    "** (1st closest cosine sim S1 x User 3's product rating + 2nd closest cosine sim S3 x User 3's product rating) / (sum of 1st and 2nd's cosine sims) **\n",
    "\n",
    "$$\\frac{0.98 \\cdot (4) + 0.72 \\cdot (5)}{0.98 + 0.72} = 4.42$$\n",
    "\n",
    "Therefore, based on this item-to-item collaborative filtering, we can see U3 is likely to rate S5 very highly at 4.42 from our calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"content-based-filtering\"></a>\n",
    "## Content-based Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "Finally, there is another method called content-based filtering. In content-based filtering, the items are broken down into \"feature baskets\". These are the characteristics that represent the item. The idea is that if you like the features of song X, then finding a song that has similar characteristics will tell us that you're likely to like it as well.\n",
    "\n",
    "\n",
    "The quintessential example of this is Pandora with it's musical genome. Each song is rated on ~450 characteristics by a trained musicologist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"example\"></a>\n",
    "## Example \n",
    "Content-based filtering begins by mapping each item into\n",
    "a feature space. Both users and items are represented by\n",
    "vectors in this space.\n",
    "Item vectors measure the degree to which the item is\n",
    "described by each feature, and user vectors measure a\n",
    "user‚Äôs preferences for each feature.\n",
    "Ratings are generated by taking dot products of user &\n",
    "item vectors. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"http://i.imgur.com/NzHksKK.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"independent-exercise\"></a>\n",
    "## Independent Exercise\n",
    "---\n",
    "\n",
    "Write a function that takes in a utility matrix with users along the index and songs along the columns as seen above in the item-to-item filtering example. The function should accept a target user and song (as strings) that it will return a rating for. \n",
    "\n",
    "Use the following as your utility matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "hideCode": true,
    "hidePrompt": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>U1</th>\n",
       "      <th>U2</th>\n",
       "      <th>U3</th>\n",
       "      <th>U4</th>\n",
       "      <th>U5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     U1   U2   U3   U4   U5\n",
       "S1  2.0  NaN  4.0  NaN  5.0\n",
       "S2  NaN  3.0  NaN  3.0  NaN\n",
       "S3  1.0  NaN  5.0  NaN  4.0\n",
       "S4  NaN  4.0  4.0  4.0  NaN\n",
       "S5  3.0  NaN  NaN  NaN  5.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'U1':[2 , None, 1, None, 3], \n",
    "                   'U2': [None, 3, None, 4, None],\n",
    "                   'U3': [4, None, 5, 4, None], \n",
    "                   'U4': [None, 3, None, 4, None], \n",
    "                   'U5': [5, None, 4, None, 5]},\n",
    "                  index = ['S1', 'S2', 'S3', 'S4', 'S5'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"conclusion\"></a>\n",
    "## Conclusion\n",
    "---\n",
    "\n",
    "We have looked at the major types of recommender systems in this lesson. Let's quickly wrap up by looking at the pros and cons of each.\n",
    "\n",
    "#### Collaborative Filtering \n",
    "\n",
    "Pros:\n",
    "- No need to hand craft features\n",
    "\n",
    "Cons:\n",
    "- Needs a large existing set of ratings (cold-start problem)\n",
    "- Sparsity occurs when the number of items far exceeds what a person could purchase\n",
    "\n",
    "#### Content-based Filtering\n",
    "\n",
    "Pros:\n",
    "- No need for a large number of users\n",
    "\n",
    "Cons:\n",
    "- Lacks serendipity\n",
    "- May be difficult to generate the right features\n",
    "- Hard to create cross-content recommendations (different feature spaces)\n",
    "\n",
    "In fact, the best solution -- and the one most likely in use in any large-scale, production system is a combination of both of these. This is known as a **hybrid system**. By combining the two systems, you can get the best of both worlds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"extra-practice\"></a>\n",
    "## Extra Practice\n",
    "---\n",
    "\n",
    "Using the [MovieLens dataset](https://grouplens.org/datasets/movielens/100k/), experiment with building a recommender system. Check the \"Additional Resources\" for more information and some considerations on how to evaluate these systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id=\"additional-resources\"></a>\n",
    "## Additional Resources\n",
    "---\n",
    "\n",
    "- [Wharton Study of Recommender Systems](http://knowledge.wharton.upenn.edu/article/recommended-for-you-how-well-does-personalized-marketing-work/)\n",
    "- [Netflix Recommendations](https://www.rtinsights.com/netflix-recommendations-machine-learning-algorithms/)\n",
    "- [Netflix Paper](http://dl.acm.org/citation.cfm?id=2843948)\n",
    "- [NY Times Rec System](https://open.blogs.nytimes.com/2015/08/11/building-the-next-new-york-times-recommendation-engine)\n",
    "- [Evaluating Rec Systems](https://www.quora.com/How-do-you-measure-and-evaluate-the-quality-of-recommendation-engines)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
