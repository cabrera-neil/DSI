{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Natural Language Processing Lab\n",
    "\n",
    "_Authors: Dave Yerrington (SF)_\n",
    "\n",
    "---\n",
    "\n",
    "In this lab, we'll explore scikit-learn and NLTK's capabilities for processing text even further. We'll use the 20 newsgroups data set, which is provided by scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standard data science imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Getting the scikit-learn data set:\n",
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Use the `fetch_20newsgroups` function to download a training and testing set.\n",
    "\n",
    "Look up the function documentation for how to grab the data.\n",
    "\n",
    "You should pull these categories:\n",
    "- `alt.atheism`\n",
    "- `talk.religion.misc`\n",
    "- `comp.graphics`\n",
    "- `sci.space`\n",
    "\n",
    "Additionally, remove the headers, footers, and quotes using the function's `remove` keyword argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Inspect the data.\n",
    "\n",
    "We've downloaded a few `newsgroups` categories and removed their headers, footers, and quotes.\n",
    "\n",
    "Because this is a scikit-learn data set, it comes with pre-split training and testing sets (note: we were able to call \"train\" and \"test\" in subset).\n",
    "\n",
    "Let's inspect them.\n",
    "\n",
    "1) What data type is `data_train`?\n",
    "- Is it a list? A dictionary? What else?\n",
    "- How many data points does it contain?\n",
    "- Inspect the first data point. What does it look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Create a bag-of-words model.\n",
    "\n",
    "Let's train a model using a simple count vectorizer.\n",
    "\n",
    "1) Initialize a standard CountVectorizer and fit the training data.\n",
    "- How big is the feature dictionary?\n",
    "- Eliminate English stop words.\n",
    "- Is the dictionary smaller?\n",
    "- Transform the training data using the trained vectorizer.\n",
    "- Evaluate the performance of a logistic regression on the features extracted by the CountVectorizer.\n",
    "    - You will have to transform the `test_set`, too. Be careful to use the trained vectorizer without refitting it.\n",
    "\n",
    "**Bonus**\n",
    "- Try a couple of modifications:\n",
    "    - Restrict the `max_features`.\n",
    "    - Change the `max_df` and `min_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Test Out Hashing and TF-IDF.\n",
    "\n",
    "Let's see if hashing or TF-IDF improves our accuracy.\n",
    "\n",
    "1) Initialize a HashingVectorizer and repeat the test with no restriction on the number of features.\n",
    "- Does the score improve with respect to the CountVectorizer?\n",
    "- Print out the number of features for this model.\n",
    "- Initialize a TF-IDF vectorizer and repeat the analysis above.\n",
    "- Print out the number of features for this model.\n",
    "\n",
    "**Bonus**\n",
    "- Change the parameters of either (or both) models to improve your score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
