{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# PCA Lab: PCA Visualization and Horn's Parallel Analysis\n",
    "\n",
    "_Author: Kiefer Katovich (SF)_\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outline:**\n",
    "\n",
    "- [Part I](#parti): Guided PCA example with the [heptathlon performance data set](./datasets/heptathlon.csv).\n",
    "- [Part II](#partii): Try PCA yourself with the [wine quality data set](./datasets/wine_quality.csv).\n",
    "- [Part III](#partiii): Use Horn's parallel analysis to select the number of components.\n",
    "\n",
    "**In this lab, we will:**\n",
    "\n",
    "- Practice cleaning data.\n",
    "- Perform PCA and interpret the principal components.\n",
    "- Validate PCA results using visualizations and intuition.\n",
    "- Select the number of principal components using elbow plots and Horn's parallel analysis.\n",
    "\n",
    "_Horn's parallel analysis_ is a way to determine how many components you should keep after performing PCA on your data. Essentially, it will tell you which of your components are likely noise and can therefore be discarded.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<a id=\"parti\"></a>\n",
    "# Part I: Heptathlon Data Set\n",
    "\n",
    "\n",
    "### 1) Load packages and heptathlon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The athlete names make a natural index and are non-numeric,\n",
    "#   so there’s no need to exclude them when creating matrices.\n",
    "hep = pd.read_csv('./datasets/heptathlon.csv', index_col=0)\n",
    "\n",
    "hep.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Create a DataFrame that excludes `athlete` and `score`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check the number of entries, the number of null values, and the proper data types.\n",
    "hep.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that in some events, a high number is good, whereas in others it’s bad.\n",
    "# - Javelin is based on distance thrown (higher is better).\n",
    "# - Shot is based on distance thrown (higher is better).\n",
    "# - Long jump is based on distance jumped (higher is better).\n",
    "\n",
    "\n",
    "# Problem: Running events are based on time taken (lower is better).\n",
    "#   - So, we'll normalize to m/s (higher is better).\n",
    "\n",
    "hep['hurdles'] = 110. / hep['hurdles']\n",
    "hep['run200m'] = 200. / hep['run200m']\n",
    "hep['run800m'] = 800. / hep['run800m']\n",
    "\n",
    "hep.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Examine the correlation between the different events.\n",
    "\n",
    "Plot a heat map if you want to visualize the correlation. What does the correlation matrix tell you?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note that all correlations are positive.** Why? \n",
    "\n",
    "Recall that we altered the data such that higher numbers always indicate a higher score and likely a better athlete overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into features and targets.\n",
    "#   - You can control the order of the event columns by changing their positions here:\n",
    "\n",
    "EVENT_NAMES = ['hurdles', 'run200m', 'run800m', 'highjump', 'shot', 'longjump', 'javelin']\n",
    "TARGET_NAMES = ['score']\n",
    "\n",
    "X = hep[EVENT_NAMES]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Fit a PCA on the standardized data using scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(Xn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1_ev = pca.components_[0]\n",
    "\n",
    "# A quick way of viewing, rather than looping through each feature:\n",
    "pd.Series(pc1_ev, index=EVENT_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc2_ev = pca.components_[1]\n",
    "\n",
    "pd.Series(pc2_ev, index=EVENT_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6) Create a DataFrame with the principal components.\n",
    "\n",
    "Add back in the `athlete` and `score` columns from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.components_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "events.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hep_pcs = pca.transform(Xn)\n",
    "hep_pcs = pd.DataFrame(hep_pcs, \n",
    "                       columns=['PC'+str(i+1) for i in range(len(EVENT_NAMES))],\n",
    "                       index=hep.index)\n",
    "hep_pcs['score'] = hep['score']\n",
    "hep_pcs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Always make sure you verify that your numbers are correct as often as possible!\n",
    "#   - At a minimum, let's ensure the athletes and scores still match up.\n",
    "hep.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7) Plot the explained variance (ratio) of your components.\n",
    "\n",
    "Explain what this chart tells you about your components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_var = pca.explained_variance_ratio_\n",
    "exp_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax.plot(range(1, len(exp_var)+1), exp_var, lw=2)\n",
    "ax.scatter(range(1, len(exp_var)+1), exp_var, s=120)\n",
    "ax.set_title('Explained variance pct\\n', fontsize=20)\n",
    "ax.set_xlabel('Principal Component', fontsize=16)\n",
    "ax.set_ylabel('Variance Explained (%)', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8) Print out the weights/eigenvectors (`.components_` ) with their corresponding variables for PC1 and PC2.\n",
    "\n",
    "Based on how the original variables are weighted to calculate the components, how would you describe PC1 and PC2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder of PC1 and PC2:\n",
    "\n",
    "pd.DataFrame({'PC1': pc1_ev, 'PC2': pc2_ev},\n",
    "             index=EVENT_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PC1 describes athletes who are below the mean in all categories. We will describe them as \"below average.”\n",
    "\n",
    "PC2 describes athletes who are the best at javelin. We will describe them as \"javelin.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9) Plot PC1 versus PC2. Which athletes are notable on each component?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "ax.scatter(hep_pcs.PC1.values, hep_pcs.PC2.values, s=0)\n",
    "\n",
    "for i, txt in enumerate(hep_pcs.index.values):\n",
    "    ax.annotate(txt, (0, 0), (hep_pcs.PC1.values[i], hep_pcs.PC2.values[i]),\n",
    "            arrowprops=dict(arrowstyle='<-', color='black', linewidth=1.5),\n",
    "            xycoords='data', textcoords='data', fontsize=12, color=\"black\")\n",
    "\n",
    "ax.set_title('PC1 (below average) vs. PC2 (javelin))')\n",
    "ax.set_xlabel('principal component 1 (below average)')\n",
    "ax.set_ylabel('principal component 2 (javelin)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10) Plot PC1 versus score. Do our results make sense?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember: **Always interpret your results**. Because we claimed that PC1 described \"below average\" athletes, we would guess that a larger PC1 value would have a lower score.\n",
    "\n",
    "Let's graph it below and see if the scores agree with our intuition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Does this graph align with our guess from above?** If not, either our calculations or interpretation are likely incorrect. Thinking about the principal components allows us to provide evidence that our results are correct and helps us better understand the PCA results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10.A) Plot PC2 versus score. What does this tell you about the relationship between the events and the score?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider how an athlete's score would be affected if they are better at javelin (our interpretation of PC2). After you understand how score _should be_ affected by PC2, look at the graph below. Does it align with your expectation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip:** Notice that we have an outlier in the bottom-right corner. Outliers are either genuine or an indicator of bad data. It's typically useful to find the athlete who corresponds with each outlier to determine if the data are bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"partii\"></a>\n",
    "# Part II: Wine Quality Data Set\n",
    "\n",
    "Now it's your turn! Try repeating this analysis to investigate the wine quality data set. As much as possible, try to perform the analysis without looking at what we did above. Remember that most of what we did previously was manipulating Pandas data and plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1) Load the wine quality data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = pd.read_csv('./datasets/wine_quality.csv')\n",
    "\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Subset the wine data to everything except the `red_wine` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3) Examine the correlation between variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Standardize the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Fit a PCA on the standardized data.\n",
    "\n",
    "Create a new DataFrame with the principal components and the `red_wine` column added back in from the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6) Create a DataFrame with the principal components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7) Plot the explained variance (ratio) of the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 8) Print out the component weights with their corresponding variables for PC1, PC2, and PC3.\n",
    "\n",
    "How would you label the components based on their weights?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** It's interesting to research what causes these factors in wines. For example, is sulfur dioxide added to wine or is it a natural byproduct of its ingredients? What affects how much sulfur dioxide a winemaker might add to wine? \n",
    "\n",
    "By researching these questions, you can likely find a good explanation for these principal components — beyond a bland description of the weightings. You can also use these intuitions from research (e.g., how pH and residual sugar affect sulfur dioxide) to provide evidence of the principal components' validity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 9) Plot PC1 versus PC2.\n",
    "\n",
    "- Use a regular scatterplot.\n",
    "- Vary the alpha value to see better densities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 10. Plot a Seaborn pair plot of PC1, PC2, and PC3 with `hue='red_wine'`.\n",
    "\n",
    "Do any of the components differentiate red and white wine? If so, what does this tell you about the difference between red and white wine based on the component weights? Does each plot align with your expectations based on the components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id=\"partiii\"></a>\n",
    "# Part III: Horn's Parallel Analysis\n",
    "\n",
    "You can determine the appropriate number of components to keep by using a bootstrapping procedure known as Horn's parallel analysis. This is the gold standard in determining which components aren't noise.\n",
    "\n",
    "How to perform the parallel analysis (pseudocode):\n",
    "\n",
    "    For n iterations:\n",
    "        Create normally distributed random data that are the same shape as your data.\n",
    "        Fit a PCA on the random data.\n",
    "        Pull out the eigenvalues.\n",
    "    Select a percentile of the eigenvalues as your threshold (0.5 = median, 0.95 = 95 percent confidence, etc.).\n",
    "    Plot the random component eigenvalues at that percentile against your data's PCA eigenvalues.\n",
    "    Components above the selected percentile are not noise; those that are under are.\n",
    "   \n",
    "Ultimately, we are comparing the PCA-explained variance of your data set against the PCA-explained variance of random Gaussian functions. If your PCA's explained variance is lower than that of random Gaussians, then we’ll assume these components represent noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "### 1) Write a function to perform the parallel analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with the actual algorithm.\n",
    "def horn_parallel_analysis(shape, iters=1000, percentile=95):\n",
    "    return [0.0] * shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2) Run parallel analysis for the heptathlon data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should work automatically (for 95th percentile).\n",
    "hep_pa = horn_parallel_analysis(X.shape, percentile=95)\n",
    "hep_pa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Run parallel analysis for the wine data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4) Plot the wine eigenvalues (`.variance_explained_`) against the parallel analysis random eigenvalue cut-offs.\n",
    "\n",
    "How many components are not noise, based on the chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "\n",
    "ax.plot(range(1, X.shape[1]+1), pca.explained_variance_, lw=2, marker='o')\n",
    "ax.plot(range(1, X.shape[1]+1), hep_pa, lw=2, color='darkred', marker='o')\n",
    "\n",
    "ax.set_title(\"Horns parallel analysis on heptathlon principal components\")\n",
    "ax.set_xlabel(\"Principal Component\")\n",
    "ax.set_ylabel(\"Eigenvalue\")\n",
    "\n",
    "plt.legend(['Actual PCA Variance Explained', \"Random Gaussian PCA Variance Explained\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Conclusion:** Note that the actual variance explained is lower than the variance explained of the random Gaussian variance after PC1. Hence, a reasonable set of principal components would be the first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5) Plot the wine eigenvalues (`.variance_explained_`) against the parallel analysis random eigenvalue cut-offs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
